# ğŸ©º MILK10k Skin Lesion Classification

Dá»± Ã¡n Deep Learning phÃ¢n loáº¡i tá»•n thÆ°Æ¡ng da sá»­ dá»¥ng dataset MILK10k vá»›i 11 loáº¡i cháº©n Ä‘oÃ¡n.

## ğŸ“‹ Má»¥c tiÃªu

XÃ¢y dá»±ng mÃ´ hÃ¬nh phÃ¢n loáº¡i Ä‘a nhÃ£n (multi-label classification) cho 11 loáº¡i tá»•n thÆ°Æ¡ng da:
- AKIEC: Actinic keratosis / intraepidermal carcinoma
- BCC: Basal cell carcinoma
- BEN_OTH: Other benign proliferations
- BKL: Benign keratinocytic lesion
- DF: Dermatofibroma
- INF: Inflammatory and infectious conditions
- MAL_OTH: Other malignant proliferations
- MEL: Melanoma
- NV: Melanocytic nevus
- SCCKA: Squamous cell carcinoma / keratoacanthoma
- VASC: Vascular lesions and hemorrhage

## ğŸ“Š Dataset

- **Training**: 5,240 lesions (10,480 images)
- **Test**: 479 lesions (958 images)
- Má»—i lesion cÃ³ 2 áº£nh: Clinical close-up + Dermatoscopic
- Metadata: Age, sex, skin tone, anatomical site, MONET scores

## ğŸ—ï¸ Cáº¥u trÃºc Project

```
DEEP_LEARNING/
â”œâ”€â”€ dataset/                          # Dá»¯ liá»‡u gá»‘c
â”‚   â”œâ”€â”€ MILK10k_Training_GroundTruth.csv
â”‚   â”œâ”€â”€ MILK10k_Training_Metadata.csv
â”‚   â”œâ”€â”€ MILK10k_Training_Supplement.csv
â”‚   â”œâ”€â”€ MILK10k_Training_Input/       # áº¢nh training
â”‚   â””â”€â”€ MILK10k_Test_Input/           # áº¢nh test
â”‚
â”œâ”€â”€ preprocessed_data/                # Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ val/
â”‚   â””â”€â”€ metadata.csv
â”‚
â”œâ”€â”€ src/                              # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                     # Configuration
â”‚   â”œâ”€â”€ data_preprocessing.py         # Tiá»n xá»­ lÃ½ dá»¯ liá»‡u
â”‚   â”œâ”€â”€ dataset.py                    # Dataset & DataLoader
â”‚   â”œâ”€â”€ augmentation.py               # Data augmentation
â”‚   â”œâ”€â”€ models.py                     # Kiáº¿n trÃºc mÃ´ hÃ¬nh
â”‚   â”œâ”€â”€ train.py                      # Training pipeline
â”‚   â”œâ”€â”€ evaluate.py                   # Evaluation metrics
â”‚   â””â”€â”€ utils.py                      # Utilities
â”‚
â”œâ”€â”€ notebooks/                        # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_EDA.ipynb                  # Exploratory Data Analysis
â”‚   â”œâ”€â”€ 02_Preprocessing.ipynb        # Data preprocessing
â”‚   â”œâ”€â”€ 03_Training.ipynb             # Model training
â”‚   â””â”€â”€ 04_Evaluation.ipynb           # Model evaluation
â”‚
â”œâ”€â”€ models/                           # Saved models
â”‚   â””â”€â”€ checkpoints/
â”‚
â”œâ”€â”€ results/                          # Káº¿t quáº£
â”‚   â”œâ”€â”€ predictions/
â”‚   â”œâ”€â”€ visualizations/
â”‚   â””â”€â”€ metrics/
â”‚
â”œâ”€â”€ logs/                             # Training logs
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ HÆ°á»›ng dáº«n sá»­ dá»¥ng

### 1. CÃ i Ä‘áº·t mÃ´i trÆ°á»ng

```bash
# Táº¡o conda environment
conda create -n milk10k python=3.10
conda activate milk10k

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt
```

### 2. Tiá»n xá»­ lÃ½ dá»¯ liá»‡u

```bash
python src/data_preprocessing.py
```

Káº¿t quáº£:
- `preprocessed_data/train_data.csv`: 4,192 samples
- `preprocessed_data/val_data.csv`: 1,048 samples  
- `preprocessed_data/class_weights.json`: Trá»ng sá»‘ cho class imbalance

### 3. KhÃ¡m phÃ¡ dá»¯ liá»‡u (Optional)

```bash
jupyter notebook notebooks/EDA.ipynb
```

### 4. Training model

**LÆ°u Ã½**: Training yÃªu cáº§u GPU máº¡nh (recommended: RTX 3060+, 8GB+ VRAM)

```bash
python src/train.py
```

Cáº¥u hÃ¬nh máº·c Ä‘á»‹nh:
- Model: EfficientNet-B3
- Image size: 384Ã—384
- Batch size: 16
- Epochs: 100 (vá»›i early stopping patience=15)
- Loss: Focal Loss vá»›i class weights
- Optimizer: AdamW (lr=1e-4, weight_decay=1e-5)
- Mixed precision training (AMP)
- TensorBoard logging

Káº¿t quáº£ training:
- `models/best_model.pth`: Model tá»‘t nháº¥t theo Macro F1
- `models/training_history.csv`: Lá»‹ch sá»­ training
- `logs/`: TensorBoard logs

Xem training progress:
```bash
tensorboard --logdir=logs
```

### 5. Inference & Generate Submission

Sau khi training xong, táº¡o file submission:

```bash
# Prediction thÃ´ng thÆ°á»ng
python src/generate_submission.py --model_path models/best_model.pth

# Vá»›i Test Time Augmentation (TTA) - tá»‘t hÆ¡n nhÆ°ng cháº­m hÆ¡n
python src/generate_submission.py --model_path models/best_model.pth --use_tta
```

Káº¿t quáº£:
- `results/submission.csv`: File submission chuáº©n
- `results/submission_tta.csv`: File submission vá»›i TTA

### 6. Evaluation (Optional)

ÄÃ¡nh giÃ¡ model trÃªn validation set:

```bash
python src/evaluate.py --model_path models/best_model.pth
```

## ğŸ“ˆ Evaluation Metric

- **Primary**: Macro F1 Score
- **Threshold**: 0.5 cho binary prediction
- Multi-label: Má»™t lesion cÃ³ thá»ƒ Ä‘Æ°á»£c dá»± Ä‘oÃ¡n thuá»™c nhiá»u category

## ğŸ§ª Chiáº¿n lÆ°á»£c Preprocessing

1. **Image Processing**:
   - Resize vá» kÃ­ch thÆ°á»›c chuáº©n (224x224 hoáº·c 384x384)
   - Normalization theo ImageNet stats
   - Color augmentation

2. **Data Fusion**:
   - Early fusion: Concatenate 2 áº£nh
   - Late fusion: Ensemble predictions
   - Feature-level fusion

3. **Metadata Integration**:
   - MONET scores (ulceration, hair, vasculature, etc.)
   - Age, sex, skin tone, anatomical site
   - Concatenate vá»›i image features

4. **Data Augmentation**:
   - Random rotation, flip, crop
   - Color jittering
   - Cutout / MixUp

5. **Class Imbalance**:
   - Weighted loss function
   - Oversampling minority classes
   - Focal Loss

## ğŸ¯ Roadmap

- [x] Phase 1: EDA & Data Understanding
- [x] Phase 2: Data Preprocessing Pipeline
- [x] Phase 3: Baseline Model (EfficientNet-B3)
- [x] Phase 4: Multi-input Architecture (Early Fusion + Metadata)
- [x] Phase 5: Training Pipeline vá»›i Focal Loss, AMP, Early Stopping
- [x] Phase 6: Inference & Submission Generator
- [ ] Phase 7: Hyperparameter Tuning
- [ ] Phase 8: Ensemble Methods
- [ ] Phase 9: Submit to MILK10k Benchmark

## ğŸ”§ Technical Details

### Model Architecture
- **Backbone**: EfficientNet-B3 (pretrained on ImageNet)
- **Input**: 384Ã—384 RGB images
- **Fusion Strategy**: Early fusion (concatenate clinical + dermoscopic images)
- **Metadata Integration**: Concatenate vá»›i image features trÆ°á»›c classifier
- **Output**: 11-class multi-label classification
- **Total Parameters**: ~11.5M

### Training Configuration
```python
MODEL_CONFIG = {
    'architecture': 'efficientnet_b3',
    'pretrained': True,
    'use_metadata': True,
    'metadata_dim': 18,  # 4 clinical + 14 MONET scores
    'dropout': 0.3
}

TRAIN_CONFIG = {
    'batch_size': 16,
    'num_epochs': 100,
    'learning_rate': 1e-4,
    'weight_decay': 1e-5,
    'scheduler': 'cosine',
    'early_stopping_patience': 15,
    'mixed_precision': True
}

LOSS_CONFIG = {
    'use_focal_loss': True,
    'focal_gamma': 2.0,
    'use_class_weights': True
}
```

### Data Augmentation
- Training: RandomRotate90, HorizontalFlip, VerticalFlip, ShiftScaleRotate, ColorJitter, GaussNoise, CoarseDropout
- Validation/Test: Only Resize + Normalize

## ğŸ¤ HÆ°á»›ng dáº«n cho Team Members

### Náº¿u báº¡n cÃ³ GPU máº¡nh Ä‘á»ƒ train:

1. **Clone repository**:
```bash
git clone <repository-url>
cd DEEP_LEARNING
```

2. **Setup environment**:
```bash
conda create -n milk10k python=3.10
conda activate milk10k
pip install -r requirements.txt
```

3. **Download dataset** vÃ  Ä‘áº·t vÃ o thÆ° má»¥c `dataset/`

4. **Tiá»n xá»­ lÃ½ dá»¯ liá»‡u** (náº¿u chÆ°a cÃ³ preprocessed_data):
```bash
python src/data_preprocessing.py
```

5. **Start training**:
```bash
python src/train.py
```

6. **Monitor training** vá»›i TensorBoard:
```bash
tensorboard --logdir=logs
```

7. **Generate submission** sau khi training xong:
```bash
python src/generate_submission.py --model_path models/best_model.pth --use_tta
```

8. **Push model vá» repository**:
```bash
# LÆ°u Ã½: model files ráº¥t lá»›n, cÃ¢n nháº¯c dÃ¹ng Git LFS hoáº·c upload lÃªn Google Drive
git add models/best_model.pth
git commit -m "Add trained model checkpoint"
git push
```

### Náº¿u chá»‰ muá»‘n test inference:

1. Download pretrained model tá»« team member
2. Cháº¡y inference:
```bash
python src/generate_submission.py --model_path path/to/model.pth
```

## âš™ï¸ System Requirements

### Minimum (cho inference):
- CPU: 4 cores
- RAM: 8GB
- GPU: Optional (CPU inference cháº­m nhÆ°ng váº«n cháº¡y Ä‘Æ°á»£c)

### Recommended (cho training):
- CPU: 8+ cores
- RAM: 16GB+
- GPU: NVIDIA RTX 3060 hoáº·c cao hÆ¡n (8GB+ VRAM)
- Storage: 50GB+ free space

### Training Time Estimate:
- **RTX 3060 (12GB)**: ~10-15 giá» cho 100 epochs
- **RTX 3090 (24GB)**: ~5-8 giá» cho 100 epochs
- **A100 (40GB)**: ~3-5 giá» cho 100 epochs
- **MX570 (2GB)**: ~30-40 giá» (khÃ´ng khuyáº¿n khÃ­ch)

## ğŸ“ Notes

- Dataset cÃ¢n báº±ng: Check phÃ¢n bá»‘ cÃ¡c classes
- Multi-label: Sá»­ dá»¥ng BCE Loss thay vÃ¬ CrossEntropy
- Fusion strategy quan trá»ng cho dual-image input
