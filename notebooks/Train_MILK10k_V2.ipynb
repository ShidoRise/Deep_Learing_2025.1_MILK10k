{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MILK10k Skin Lesion Classification - EfficientNetV2-L Training\n",
        "\n",
        "This notebook trains an **EfficientNetV2-L** model with **Cross-Modal Attention Fusion** for improved Macro F1 score.\n",
        "\n",
        "## Overview\n",
        "\n",
        "| Component | Value |\n",
        "|-----------|-------|\n",
        "| **Model** | EfficientNetV2-L (dual backbone) |\n",
        "| **Fusion** | Cross-Modal Attention + Gated Fusion |\n",
        "| **Image Size** | 480x480 |\n",
        "| **Loss** | Asymmetric Loss + Label Smoothing |\n",
        "| **Features** | Deep Supervision + EMA |\n",
        "| **GPU** | A100 80GB (Colab Pro) |\n",
        "| **Expected Time** | 4-5 hours |\n",
        "\n",
        "## Improvements over EfficientNet-B3\n",
        "\n",
        "1. **Larger backbone**: 120M params vs 12M (10x more capacity)\n",
        "2. **Cross-modal attention**: Clinical and dermoscopic images attend to each other\n",
        "3. **Asymmetric loss**: Better handling of class imbalance\n",
        "4. **Deep supervision**: Auxiliary heads for better gradient flow\n",
        "5. **EMA**: Smoother weight updates for better generalization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup Environment\n",
        "\n",
        "Check GPU and system specifications.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi\n",
        "\n",
        "# Check CUDA version\n",
        "!nvcc --version\n",
        "\n",
        "# Check disk space and RAM\n",
        "!df -h | grep -E 'Filesystem|/content'\n",
        "!free -h\n",
        "\n",
        "# Verify we have A100 80GB\n",
        "import subprocess\n",
        "result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv'], capture_output=True, text=True)\n",
        "print(f\"\\nGPU Info:\\n{result.stdout}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Mount Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "DRIVE_ROOT = '/content/drive/MyDrive/MILK10k_Project'\n",
        "os.makedirs(DRIVE_ROOT, exist_ok=True)\n",
        "\n",
        "print(f\"Google Drive mounted!\")\n",
        "print(f\"Project root: {DRIVE_ROOT}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install -q timm albumentations tensorboard scikit-learn\n",
        "\n",
        "# Verify installations\n",
        "import torch\n",
        "import torchvision\n",
        "import timm\n",
        "import albumentations as A\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"TorchVision: {torchvision.__version__}\")\n",
        "print(f\"Timm: {timm.__version__}\")\n",
        "print(f\"Albumentations: {A.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Setup Project Files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Create working directory\n",
        "WORK_DIR = '/content/MILK10k'\n",
        "os.makedirs(WORK_DIR, exist_ok=True)\n",
        "%cd {WORK_DIR}\n",
        "\n",
        "# Copy source code from Drive\n",
        "SRC_DRIVE = f'{DRIVE_ROOT}/src'\n",
        "if os.path.exists(SRC_DRIVE):\n",
        "    !cp -r {SRC_DRIVE} {WORK_DIR}/\n",
        "    print(\"Copied src/ from Google Drive\")\n",
        "else:\n",
        "    print(\"WARNING: src/ not found in Google Drive. Please upload it first!\")\n",
        "\n",
        "# Copy preprocessed data\n",
        "PREPROCESSED_DRIVE = f'{DRIVE_ROOT}/preprocessed_data'\n",
        "if os.path.exists(PREPROCESSED_DRIVE):\n",
        "    !cp -r {PREPROCESSED_DRIVE} {WORK_DIR}/\n",
        "    print(\"Copied preprocessed_data/ from Google Drive\")\n",
        "else:\n",
        "    print(\"WARNING: preprocessed_data/ not found. Please upload it first!\")\n",
        "\n",
        "# Link dataset from Google Drive (no copy needed)\n",
        "DATASET_DRIVE = f'{DRIVE_ROOT}/dataset/MILK10k_Training_Input'\n",
        "if os.path.exists(DATASET_DRIVE):\n",
        "    os.makedirs(f'{WORK_DIR}/dataset', exist_ok=True)\n",
        "    !ln -sf {DATASET_DRIVE} {WORK_DIR}/dataset/MILK10k_Training_Input\n",
        "    print(f\"Linked dataset from Google Drive\")\n",
        "else:\n",
        "    print(f\"WARNING: Dataset not found at: {DATASET_DRIVE}\")\n",
        "\n",
        "# Create output directories\n",
        "os.makedirs('models', exist_ok=True)\n",
        "os.makedirs('logs', exist_ok=True)\n",
        "os.makedirs('results', exist_ok=True)\n",
        "\n",
        "print(f\"\\nWorking directory: {WORK_DIR}\")\n",
        "!ls -la\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Import Modules and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/MILK10k/src')\n",
        "\n",
        "# Import modules\n",
        "from src.config import *\n",
        "from src.utils import *\n",
        "from src.dataset import *\n",
        "from src.models_v2 import *\n",
        "from src.losses import *\n",
        "from src.train_v2 import TrainerV2\n",
        "from src.evaluate import *\n",
        "\n",
        "# Display V2 configuration\n",
        "print(\"=\"*60)\n",
        "print(\"EFFICIENTNETV2-L CONFIGURATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nModel Config (V2):\")\n",
        "for key, value in MODEL_CONFIG_V2.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(f\"\\nTraining Config (V2):\")\n",
        "for key, value in TRAIN_CONFIG_V2.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(f\"\\nImage Config (V2):\")\n",
        "for key, value in IMAGE_CONFIG_V2.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(f\"\\nLoss Config (V2):\")\n",
        "for key, value in LOSS_CONFIG_V2.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Load and Prepare Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "\n",
        "# Load preprocessed data\n",
        "print(\"Loading preprocessed data...\")\n",
        "train_df = pd.read_csv('preprocessed_data/train_data.csv')\n",
        "val_df = pd.read_csv('preprocessed_data/val_data.csv')\n",
        "\n",
        "print(f\"Training samples: {len(train_df):,}\")\n",
        "print(f\"Validation samples: {len(val_df):,}\")\n",
        "\n",
        "# Load class weights\n",
        "with open('preprocessed_data/class_weights.json', 'r') as f:\n",
        "    class_weights = json.load(f)\n",
        "\n",
        "print(f\"\\nClass Weights:\")\n",
        "for cat, weight in class_weights.items():\n",
        "    print(f\"  {cat}: {weight:.4f}\")\n",
        "\n",
        "# Estimate samples per class\n",
        "total_samples = len(train_df)\n",
        "samples_per_class = get_samples_per_class(class_weights, total_samples)\n",
        "print(f\"\\nEstimated samples per class: {samples_per_class}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fix Image Paths for Colab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fix_image_paths(df, dataset_root):\n",
        "    \"\"\"Fix Windows paths to work with Colab.\"\"\"\n",
        "    df = df.copy()\n",
        "    \n",
        "    for col in ['clinical_image_path', 'dermoscopic_image_path']:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].apply(lambda x: extract_relative_path(str(x), dataset_root))\n",
        "    \n",
        "    return df\n",
        "\n",
        "def extract_relative_path(path_str, dataset_root):\n",
        "    \"\"\"Extract lesion_id/image.jpg from any path format.\"\"\"\n",
        "    match = re.search(r'(IL_\\d+)[/\\\\](ISIC_\\d+\\.jpg)', path_str)\n",
        "    \n",
        "    if match:\n",
        "        lesion_id = match.group(1)\n",
        "        image_file = match.group(2)\n",
        "        return os.path.join(dataset_root, 'MILK10k_Training_Input', lesion_id, image_file)\n",
        "    else:\n",
        "        parts = re.split(r'[/\\\\]', path_str)\n",
        "        parts = [p for p in parts if p]\n",
        "        if len(parts) >= 2:\n",
        "            return os.path.join(dataset_root, 'MILK10k_Training_Input', parts[-2], parts[-1])\n",
        "        raise ValueError(f\"Cannot extract path from: {path_str}\")\n",
        "\n",
        "# Fix paths\n",
        "DATASET_ROOT = f'{WORK_DIR}/dataset'\n",
        "print(\"Fixing image paths...\")\n",
        "\n",
        "train_df = fix_image_paths(train_df, DATASET_ROOT)\n",
        "val_df = fix_image_paths(val_df, DATASET_ROOT)\n",
        "\n",
        "print(f\"\\nExample paths:\")\n",
        "print(f\"  Clinical: {train_df['clinical_image_path'].iloc[0]}\")\n",
        "print(f\"  Dermoscopic: {train_df['dermoscopic_image_path'].iloc[0]}\")\n",
        "\n",
        "# Verify paths\n",
        "sample_path = train_df['clinical_image_path'].iloc[0]\n",
        "if os.path.exists(sample_path):\n",
        "    print(f\"\\nImage paths verified!\")\n",
        "else:\n",
        "    print(f\"\\nWARNING: Image not found at {sample_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Create DataLoaders (480x480 images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimized for A100 80GB with EfficientNetV2-L\n",
        "BATCH_SIZE = TRAIN_CONFIG_V2['batch_size']  # 48 by default\n",
        "NUM_WORKERS = TRAIN_CONFIG_V2['num_workers']  # 8\n",
        "IMAGE_SIZE = IMAGE_CONFIG_V2['image_size']  # 480\n",
        "\n",
        "print(f\"Creating dataloaders for EfficientNetV2-L...\")\n",
        "print(f\"  Image size: {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  Num workers: {NUM_WORKERS}\")\n",
        "\n",
        "# Create dataloaders with larger images\n",
        "train_loader, val_loader = get_dataloaders(\n",
        "    train_df,\n",
        "    val_df,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    fusion_strategy='late',  # Always late for V2\n",
        "    use_metadata=MODEL_CONFIG_V2['use_metadata']\n",
        ")\n",
        "\n",
        "print(f\"\\nTrain DataLoader: {len(train_loader)} batches\")\n",
        "print(f\"Val DataLoader: {len(val_loader)} batches\")\n",
        "\n",
        "# Test dataloader\n",
        "print(f\"\\nTesting dataloader...\")\n",
        "for batch in train_loader:\n",
        "    images, labels, metadata = batch\n",
        "    clinical_img, dermoscopic_img = images\n",
        "    print(f\"  Clinical shape: {clinical_img.shape}\")\n",
        "    print(f\"  Dermoscopic shape: {dermoscopic_img.shape}\")\n",
        "    print(f\"  Labels shape: {labels.shape}\")\n",
        "    print(f\"  Metadata shape: {metadata.shape}\")\n",
        "    break\n",
        "print(\"DataLoader test successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Create Model (EfficientNetV2-L with Cross-Modal Attention)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get device\n",
        "device = get_device()\n",
        "\n",
        "# Create EfficientNetV2-L model\n",
        "print(\"Creating EfficientNetV2-L model with Cross-Modal Attention...\")\n",
        "model = create_model_v2(\n",
        "    architecture=MODEL_CONFIG_V2['architecture'],\n",
        "    num_classes=len(DIAGNOSIS_CATEGORIES),\n",
        "    pretrained=MODEL_CONFIG_V2['pretrained'],\n",
        "    use_metadata=MODEL_CONFIG_V2['use_metadata'],\n",
        "    metadata_dim=MODEL_CONFIG_V2['metadata_dim'],\n",
        "    dropout=MODEL_CONFIG_V2['dropout'],\n",
        "    use_auxiliary_heads=MODEL_CONFIG_V2['use_auxiliary_heads']\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params, trainable_params = count_parameters(model)\n",
        "\n",
        "print(f\"\\nModel: {MODEL_CONFIG_V2['architecture']}\")\n",
        "print(f\"Fusion: Cross-Modal Attention + Gated Fusion\")\n",
        "print(f\"Auxiliary Heads: {MODEL_CONFIG_V2['use_auxiliary_heads']}\")\n",
        "print(f\"Metadata: {MODEL_CONFIG_V2['use_metadata']}\")\n",
        "print(f\"Device: {device}\")\n",
        "print(f\"Parameters: {total_params:,} (Trainable: {trainable_params:,})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Initialize Trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set random seed\n",
        "set_seed(TRAIN_CONFIG_V2['random_seed'])\n",
        "\n",
        "# Update paths to save in Google Drive\n",
        "TRAIN_CONFIG_V2['checkpoint_dir'] = f'{DRIVE_ROOT}/models'\n",
        "TRAIN_CONFIG_V2['log_dir'] = f'{DRIVE_ROOT}/logs'\n",
        "\n",
        "os.makedirs(TRAIN_CONFIG_V2['checkpoint_dir'], exist_ok=True)\n",
        "os.makedirs(TRAIN_CONFIG_V2['log_dir'], exist_ok=True)\n",
        "\n",
        "print(f\"Creating TrainerV2...\")\n",
        "print(f\"  Checkpoint dir: {TRAIN_CONFIG_V2['checkpoint_dir']}\")\n",
        "print(f\"  Log dir: {TRAIN_CONFIG_V2['log_dir']}\")\n",
        "\n",
        "# Create trainer\n",
        "trainer = TrainerV2(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    class_weights=class_weights,\n",
        "    samples_per_class=samples_per_class,\n",
        "    device=device,\n",
        "    config=TRAIN_CONFIG_V2\n",
        ")\n",
        "\n",
        "print(f\"\\nTrainer initialized!\")\n",
        "print(f\"  Loss: {LOSS_CONFIG_V2['type']}\")\n",
        "print(f\"  Use EMA: {TRAIN_CONFIG_V2.get('use_ema', True)}\")\n",
        "print(f\"  Label Smoothing: {LOSS_CONFIG_V2.get('use_label_smoothing', True)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. TensorBoard (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {TRAIN_CONFIG_V2['log_dir']}\n",
        "\n",
        "print(\"TensorBoard loaded! View metrics above during training.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10.5 Resume Training from Checkpoint (Optional)\n",
        "\n",
        "**Skip this cell if starting fresh.** Run this cell ONLY if you want to resume from a previous checkpoint.\n",
        "\n",
        "Checkpoints are saved:\n",
        "- Every 5 epochs: `checkpoint_v2_epoch_5.pth`, `checkpoint_v2_epoch_10.pth`, etc.\n",
        "- Best model: `best_model_v2.pth`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# RESUME FROM CHECKPOINT - Only run if continuing training!\n",
        "# ============================================================\n",
        "# Comment out/skip this cell if starting fresh training\n",
        "\n",
        "RESUME_FROM_CHECKPOINT = False  # Set to True to resume\n",
        "\n",
        "if RESUME_FROM_CHECKPOINT:\n",
        "    # List available checkpoints\n",
        "    checkpoint_dir = TRAIN_CONFIG_V2['checkpoint_dir']\n",
        "    print(\"Available checkpoints:\")\n",
        "    import glob\n",
        "    checkpoints = glob.glob(f\"{checkpoint_dir}/*.pth\")\n",
        "    for cp in sorted(checkpoints):\n",
        "        print(f\"  - {os.path.basename(cp)}\")\n",
        "    \n",
        "    # Choose checkpoint to resume from (latest epoch checkpoint)\n",
        "    CHECKPOINT_FILE = \"checkpoint_v2_epoch_10.pth\"  # Change this to your checkpoint\n",
        "    checkpoint_path = f\"{checkpoint_dir}/{CHECKPOINT_FILE}\"\n",
        "    \n",
        "    if os.path.exists(checkpoint_path):\n",
        "        print(f\"\\nLoading checkpoint: {checkpoint_path}\")\n",
        "        \n",
        "        # Load checkpoint\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "        \n",
        "        # Load model weights\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        print(f\"Model weights loaded from epoch {checkpoint['epoch'] + 1}\")\n",
        "        \n",
        "        # Load optimizer state\n",
        "        trainer.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        print(\"Optimizer state loaded\")\n",
        "        \n",
        "        # Load scheduler state if available\n",
        "        if 'scheduler_state_dict' in checkpoint and checkpoint['scheduler_state_dict']:\n",
        "            trainer.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "            print(\"Scheduler state loaded\")\n",
        "        \n",
        "        # Update trainer's starting epoch\n",
        "        START_EPOCH = checkpoint['epoch'] + 1\n",
        "        print(f\"\\nResuming training from epoch {START_EPOCH + 1}\")\n",
        "        print(f\"Previous best metric: {checkpoint.get('metrics', 'N/A')}\")\n",
        "    else:\n",
        "        print(f\"Checkpoint not found: {checkpoint_path}\")\n",
        "        print(\"Starting fresh training instead.\")\n",
        "        START_EPOCH = 0\n",
        "else:\n",
        "    START_EPOCH = 0\n",
        "    print(\"Starting fresh training (RESUME_FROM_CHECKPOINT = False)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Start Training\n",
        "\n",
        "**Expected Training Time**: 4-5 hours on A100 80GB\n",
        "\n",
        "Features:\n",
        "- Mixed precision (FP16) for memory efficiency\n",
        "- EMA for smoother weights\n",
        "- Deep supervision with auxiliary heads\n",
        "- Checkpoints saved every 5 epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start training (supports resume from checkpoint)\n",
        "print(\"Starting EfficientNetV2-L training...\")\n",
        "print(\"This will take approximately 4-5 hours on A100 80GB.\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check if resuming from checkpoint\n",
        "if RESUME_FROM_CHECKPOINT and 'START_EPOCH' in dir() and START_EPOCH > 0:\n",
        "    # Get best F1 from checkpoint if available\n",
        "    best_f1_resume = checkpoint.get('metrics', 0.0)\n",
        "    if isinstance(best_f1_resume, dict):\n",
        "        best_f1_resume = best_f1_resume.get('macro_f1', 0.0)\n",
        "    history = trainer.train(start_epoch=START_EPOCH, best_f1=best_f1_resume)\n",
        "else:\n",
        "    history = trainer.train()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING COMPLETED!\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. View Training Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load training history\n",
        "history_df = pd.read_csv(f'{TRAIN_CONFIG_V2[\"checkpoint_dir\"]}/training_history_v2.csv')\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"TRAINING SUMMARY - EfficientNetV2-L\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nTotal epochs: {len(history_df)}\")\n",
        "print(f\"Best Macro F1: {history_df['val_f1_macro'].max():.4f}\")\n",
        "print(f\"Best Micro F1: {history_df['val_f1_micro'].max():.4f}\")\n",
        "print(f\"Final Train Loss: {history_df['train_loss'].iloc[-1]:.4f}\")\n",
        "print(f\"Final Val Loss: {history_df['val_loss'].iloc[-1]:.4f}\")\n",
        "\n",
        "# Compare with B3 baseline\n",
        "print(f\"\\n--- Comparison with EfficientNet-B3 ---\")\n",
        "print(f\"B3 Best Macro F1: ~0.50\")\n",
        "print(f\"V2-L Best Macro F1: {history_df['val_f1_macro'].max():.4f}\")\n",
        "improvement = (history_df['val_f1_macro'].max() - 0.50) / 0.50 * 100\n",
        "print(f\"Improvement: {improvement:+.1f}%\")\n",
        "\n",
        "# Plot training curves\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Loss curves\n",
        "axes[0, 0].plot(history_df['train_loss'], label='Train Loss', linewidth=2)\n",
        "axes[0, 0].plot(history_df['val_loss'], label='Val Loss', linewidth=2)\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('Loss')\n",
        "axes[0, 0].set_title('Training and Validation Loss')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# F1 scores\n",
        "axes[0, 1].plot(history_df['val_f1_macro'], label='Macro F1', linewidth=2, color='green')\n",
        "axes[0, 1].plot(history_df['val_f1_micro'], label='Micro F1', linewidth=2, color='blue')\n",
        "axes[0, 1].axhline(y=0.50, color='red', linestyle='--', label='B3 Baseline')\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('F1 Score')\n",
        "axes[0, 1].set_title('Validation F1 Scores')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Learning rate\n",
        "axes[1, 0].plot(history_df['learning_rate'], linewidth=2, color='orange')\n",
        "axes[1, 0].set_xlabel('Epoch')\n",
        "axes[1, 0].set_ylabel('Learning Rate')\n",
        "axes[1, 0].set_title('Learning Rate Schedule')\n",
        "axes[1, 0].set_yscale('log')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# F1 improvement\n",
        "best_so_far = history_df['val_f1_macro'].cummax()\n",
        "axes[1, 1].fill_between(range(len(best_so_far)), 0.50, best_so_far, alpha=0.3, color='green')\n",
        "axes[1, 1].plot(best_so_far, linewidth=2, color='green', label='Best Macro F1')\n",
        "axes[1, 1].axhline(y=0.50, color='red', linestyle='--', label='B3 Baseline')\n",
        "axes[1, 1].set_xlabel('Epoch')\n",
        "axes[1, 1].set_ylabel('Macro F1')\n",
        "axes[1, 1].set_title('Macro F1 Improvement')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{DRIVE_ROOT}/training_curves_v2.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nTraining curves saved to: {DRIVE_ROOT}/training_curves_v2.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Save Model Info\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "best_epoch = history_df['val_f1_macro'].idxmax()\n",
        "best_macro_f1 = history_df['val_f1_macro'].max()\n",
        "best_micro_f1 = history_df.loc[best_epoch, 'val_f1_micro']\n",
        "\n",
        "model_info = f\"\"\"# EfficientNetV2-L Training Results\n",
        "\n",
        "**Date**: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
        "**GPU**: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\n",
        "**Total Epochs**: {len(history_df)}\n",
        "**Best Epoch**: {best_epoch + 1}\n",
        "**Best Macro F1**: {best_macro_f1:.4f}\n",
        "**Best Micro F1**: {best_micro_f1:.4f}\n",
        "\n",
        "## Model Configuration\n",
        "- Architecture: {MODEL_CONFIG_V2['architecture']}\n",
        "- Fusion: Cross-Modal Attention + Gated Fusion\n",
        "- Image Size: {IMAGE_CONFIG_V2['image_size']}x{IMAGE_CONFIG_V2['image_size']}\n",
        "- Batch Size: {TRAIN_CONFIG_V2['batch_size']}\n",
        "- Loss: {LOSS_CONFIG_V2['type']}\n",
        "\n",
        "## Files\n",
        "- Best Model: {TRAIN_CONFIG_V2['checkpoint_dir']}/best_model_v2.pth\n",
        "- Training History: {TRAIN_CONFIG_V2['checkpoint_dir']}/training_history_v2.csv\n",
        "\"\"\"\n",
        "\n",
        "info_path = f'{DRIVE_ROOT}/MODEL_INFO_V2.md'\n",
        "with open(info_path, 'w') as f:\n",
        "    f.write(model_info)\n",
        "\n",
        "print(model_info)\n",
        "print(f\"\\nModel info saved to: {info_path}\")\n",
        "\n",
        "# Print file locations\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Files saved in Google Drive:\")\n",
        "print(f\"  - {TRAIN_CONFIG_V2['checkpoint_dir']}/best_model_v2.pth\")\n",
        "print(f\"  - {TRAIN_CONFIG_V2['checkpoint_dir']}/training_history_v2.csv\")\n",
        "print(f\"  - {DRIVE_ROOT}/training_curves_v2.png\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Training Complete!\n",
        "\n",
        "### Key Results\n",
        "- EfficientNetV2-L with Cross-Modal Attention\n",
        "- Improved Macro F1 over baseline\n",
        "- Model saved to Google Drive\n",
        "\n",
        "### Next Steps\n",
        "1. Run inference with TTA (Test-Time Augmentation)\n",
        "2. Optimize thresholds per class\n",
        "3. Ensemble with EfficientNet-B3 for final submission\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
