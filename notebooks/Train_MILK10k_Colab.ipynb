{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24287c66",
   "metadata": {},
   "source": [
    "# ü©∫ MILK10k Skin Lesion Classification - Training on Google Colab\n",
    "\n",
    "This notebook trains a deep learning model for skin lesion classification using the MILK10k dataset on Google Colab with GPU acceleration.\n",
    "\n",
    "## üìã Overview\n",
    "\n",
    "- **Model**: EfficientNet-B3 with metadata fusion\n",
    "- **Dataset**: MILK10k (4,192 train + 1,048 validation)\n",
    "- **Task**: Multi-label classification (11 diagnosis categories)\n",
    "- **Loss**: Focal Loss with class weights\n",
    "- **Training**: Mixed precision (AMP) + Early stopping\n",
    "\n",
    "## üöÄ Before Running\n",
    "\n",
    "1. **Set Runtime to GPU**: Runtime ‚Üí Change runtime type ‚Üí GPU (T4 or better)\n",
    "2. **Upload to Google Drive**:\n",
    "   - `preprocessed_data/` folder (train_data.csv, val_data.csv, class_weights.json)\n",
    "   - Dataset images (or download from source)\n",
    "   - Project code files\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8c4c4d",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup Google Colab Environment\n",
    "\n",
    "Check GPU availability and system specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cbe5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "# Check CUDA version\n",
    "!nvcc --version\n",
    "\n",
    "# Check disk space\n",
    "!df -h | grep -E 'Filesystem|/content'\n",
    "\n",
    "# Check RAM\n",
    "!free -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770880ba",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Mount Google Drive\n",
    "\n",
    "Mount Google Drive to access datasets and save results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3ab8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set up project paths (adjust these to match your Google Drive structure)\n",
    "import os\n",
    "DRIVE_ROOT = '/content/drive/MyDrive/MILK10k_Project'\n",
    "os.makedirs(DRIVE_ROOT, exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Google Drive mounted!\")\n",
    "print(f\"üìÅ Project root: {DRIVE_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2121c2",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Install Dependencies\n",
    "\n",
    "Install PyTorch with CUDA support and other required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c7d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q timm albumentations tensorboard scikit-learn\n",
    "\n",
    "# Verify installations\n",
    "import torch\n",
    "import torchvision\n",
    "import timm\n",
    "import albumentations as A\n",
    "\n",
    "print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
    "print(f\"‚úÖ TorchVision: {torchvision.__version__}\")\n",
    "print(f\"‚úÖ Timm: {timm.__version__}\")\n",
    "print(f\"‚úÖ Albumentations: {A.__version__}\")\n",
    "print(f\"‚úÖ CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úÖ CUDA Version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38361a9",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Setup Project Files\n",
    "\n",
    "Clone repository or upload project files to Colab workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072db5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Clone from GitHub (if repository is public)\n",
    "# !git clone https://github.com/YOUR_USERNAME/YOUR_REPO.git\n",
    "# %cd YOUR_REPO\n",
    "\n",
    "# Option 2: Copy from Google Drive (recommended)\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Create working directory\n",
    "WORK_DIR = '/content/MILK10k'\n",
    "os.makedirs(WORK_DIR, exist_ok=True)\n",
    "%cd {WORK_DIR}\n",
    "\n",
    "# Copy source code from Drive\n",
    "SRC_DRIVE = f'{DRIVE_ROOT}/src'\n",
    "if os.path.exists(SRC_DRIVE):\n",
    "    !cp -r {SRC_DRIVE} {WORK_DIR}/\n",
    "    print(\"‚úÖ Copied src/ from Google Drive\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è src/ not found in Google Drive. Please upload it first!\")\n",
    "\n",
    "# Copy preprocessed data\n",
    "PREPROCESSED_DRIVE = f'{DRIVE_ROOT}/preprocessed_data'\n",
    "if os.path.exists(PREPROCESSED_DRIVE):\n",
    "    !cp -r {PREPROCESSED_DRIVE} {WORK_DIR}/\n",
    "    print(\"‚úÖ Copied preprocessed_data/ from Google Drive\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è preprocessed_data/ not found. Please upload it first!\")\n",
    "\n",
    "# Option A: Use dataset directly from Google Drive (slower but saves space)\n",
    "DATASET_DRIVE = f'{DRIVE_ROOT}/dataset/MILK10k_Training_Input'\n",
    "if os.path.exists(DATASET_DRIVE):\n",
    "    # Create symlink to access images from Drive (faster than copying)\n",
    "    !ln -s {DATASET_DRIVE} {WORK_DIR}/dataset/MILK10k_Training_Input\n",
    "    print(f\"‚úÖ Linked dataset from Google Drive (no copy needed)\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Dataset not found at: {DATASET_DRIVE}\")\n",
    "    print(\"   Please upload MILK10k_Training_Input/ to your Google Drive!\")\n",
    "\n",
    "# Option B: Copy dataset to local Colab storage (faster but uses ~5-10GB)\n",
    "# Uncomment if you want faster I/O during training:\n",
    "# DATASET_DRIVE = f'{DRIVE_ROOT}/dataset'\n",
    "# if os.path.exists(DATASET_DRIVE):\n",
    "#     print(\"Copying dataset to Colab storage (this may take 10-15 minutes)...\")\n",
    "#     !cp -r {DATASET_DRIVE} {WORK_DIR}/\n",
    "#     print(\"‚úÖ Copied dataset to Colab local storage\")\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "print(f\"\\nüìÅ Working directory: {WORK_DIR}\")\n",
    "print(f\"üìÇ Contents:\")\n",
    "!ls -la\n",
    "print(f\"\\nüì∏ Dataset path will be: {WORK_DIR}/dataset/MILK10k_Training_Input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7550b9",
   "metadata": {},
   "source": [
    "### Alternative: Extract Dataset from ZIP (Faster Setup)\n",
    "\n",
    "If you uploaded a ZIP file to Google Drive, use this to extract it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b26ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this if you uploaded a ZIP file to Google Drive\n",
    "\n",
    "# ZIP_PATH = f'{DRIVE_ROOT}/MILK10k_Training_Input.zip'\n",
    "# \n",
    "# if os.path.exists(ZIP_PATH):\n",
    "#     print(f\"Extracting dataset from ZIP (this may take 5-10 minutes)...\")\n",
    "#     !unzip -q {ZIP_PATH} -d {WORK_DIR}/dataset/\n",
    "#     print(f\"‚úÖ Dataset extracted to: {WORK_DIR}/dataset/\")\n",
    "# else:\n",
    "#     print(f\"‚ö†Ô∏è ZIP file not found at: {ZIP_PATH}\")\n",
    "\n",
    "print(\"‚ÑπÔ∏è Skipped (using direct Drive access or already extracted)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2307752",
   "metadata": {},
   "source": [
    "### Alternative: Download from Kaggle (Best for Large Datasets)\n",
    "\n",
    "If dataset is hosted on Kaggle, use this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d85c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and configure if downloading from Kaggle\n",
    "\n",
    "# # Install Kaggle API\n",
    "# !pip install -q kaggle\n",
    "# \n",
    "# # Upload your kaggle.json to Colab or use the file uploader\n",
    "# from google.colab import files\n",
    "# files.upload()  # Upload kaggle.json\n",
    "# \n",
    "# !mkdir -p ~/.kaggle\n",
    "# !cp kaggle.json ~/.kaggle/\n",
    "# !chmod 600 ~/.kaggle/kaggle.json\n",
    "# \n",
    "# # Download dataset (replace with actual dataset name)\n",
    "# !kaggle datasets download -d YOUR_USERNAME/milk10k-dataset\n",
    "# !unzip -q milk10k-dataset.zip -d {WORK_DIR}/dataset/\n",
    "# \n",
    "# print(\"‚úÖ Dataset downloaded from Kaggle\")\n",
    "\n",
    "print(\"‚ÑπÔ∏è Skipped (using Google Drive or already downloaded)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f563d1",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Load Configuration\n",
    "\n",
    "Import configuration and verify settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa476ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/MILK10k/src')\n",
    "\n",
    "# Import all modules\n",
    "from src.config import *\n",
    "from src.utils import *\n",
    "from src.dataset import *\n",
    "from src.models import *\n",
    "from src.evaluate import *\n",
    "\n",
    "# Display configuration\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìä Model Config:\")\n",
    "for key, value in MODEL_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nüéØ Training Config:\")\n",
    "for key, value in TRAIN_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nüñºÔ∏è Image Config:\")\n",
    "for key, value in IMAGE_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è Loss Config:\")\n",
    "for key, value in LOSS_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nüìÇ Diagnosis Categories ({len(DIAGNOSIS_CATEGORIES)}):\")\n",
    "for cat in DIAGNOSIS_CATEGORIES:\n",
    "    print(f\"  - {cat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0d32b0",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Load Dataset\n",
    "\n",
    "Load preprocessed training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d0cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load preprocessed data\n",
    "print(\"Loading preprocessed data...\")\n",
    "train_df = pd.read_csv('preprocessed_data/train_data.csv')\n",
    "val_df = pd.read_csv('preprocessed_data/val_data.csv')\n",
    "\n",
    "print(f\"‚úÖ Training samples: {len(train_df):,}\")\n",
    "print(f\"‚úÖ Validation samples: {len(val_df):,}\")\n",
    "\n",
    "# Load class weights\n",
    "with open('preprocessed_data/class_weights.json', 'r') as f:\n",
    "    class_weights = json.load(f)\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è Class Weights:\")\n",
    "for cat, weight in class_weights.items():\n",
    "    print(f\"  {cat}: {weight:.4f}\")\n",
    "\n",
    "# Display sample data\n",
    "print(f\"\\nüìä Training Data Sample:\")\n",
    "print(train_df.head(3))\n",
    "\n",
    "# Check class distribution\n",
    "print(f\"\\nüìà Label Distribution (Training):\")\n",
    "label_counts = train_df[DIAGNOSIS_CATEGORIES].sum()\n",
    "for cat in DIAGNOSIS_CATEGORIES:\n",
    "    count = label_counts[cat]\n",
    "    pct = (count / len(train_df)) * 100\n",
    "    print(f\"  {cat}: {count:,} ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd45a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def fix_image_paths(df, dataset_root):\n",
    "    \"\"\"\n",
    "    Fix Windows absolute paths to work with Colab's dataset location.\n",
    "    \n",
    "    Extracts only the relative path (lesion_id/image.jpg) and reconstructs\n",
    "    with the correct dataset root path.\n",
    "    \n",
    "    Example:\n",
    "        D:\\\\PYTHON\\\\DEEP_LEARNING\\\\dataset\\\\MILK10k_Training_Input\\\\IL_8583674\\\\ISIC_8570261.jpg\n",
    "        -> /content/MILK10k/dataset/MILK10k_Training_Input/IL_8583674/ISIC_8570261.jpg\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    for col in ['clinical_image_path', 'dermoscopic_image_path']:\n",
    "        if col in df.columns:\n",
    "            # Extract just the lesion_id and filename from Windows paths\n",
    "            # Use regex to find pattern: IL_XXXXXXX/ISIC_XXXXXXX.jpg\n",
    "            df[col] = df[col].apply(lambda x: \n",
    "                extract_relative_path(str(x), dataset_root)\n",
    "            )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extract_relative_path(path_str, dataset_root):\n",
    "    \"\"\"\n",
    "    Extract lesion_id/image.jpg from any path format (Windows or Linux).\n",
    "    \n",
    "    Examples:\n",
    "        D:\\\\PYTHON\\\\...\\\\IL_8583674\\\\ISIC_8570261.jpg -> IL_8583674/ISIC_8570261.jpg\n",
    "        /some/path/IL_8583674/ISIC_8570261.jpg -> IL_8583674/ISIC_8570261.jpg\n",
    "    \"\"\"\n",
    "    # Use regex to extract the lesion_id and image filename\n",
    "    # Pattern: IL_XXXXXXX (lesion ID) followed by / or \\ and then ISIC_XXXXXXX.jpg (image file)\n",
    "    match = re.search(r'(IL_\\d+)[/\\\\](ISIC_\\d+\\.jpg)', path_str)\n",
    "    \n",
    "    if match:\n",
    "        lesion_id = match.group(1)\n",
    "        image_file = match.group(2)\n",
    "        # Build the correct path\n",
    "        return os.path.join(dataset_root, 'MILK10k_Training_Input', lesion_id, image_file)\n",
    "    else:\n",
    "        # If pattern doesn't match, try to extract last 2 parts using both separators\n",
    "        parts = re.split(r'[/\\\\]', path_str)\n",
    "        parts = [p for p in parts if p]  # Remove empty parts\n",
    "        if len(parts) >= 2:\n",
    "            return os.path.join(dataset_root, 'MILK10k_Training_Input', parts[-2], parts[-1])\n",
    "        else:\n",
    "            raise ValueError(f\"Cannot extract lesion_id and image from path: {path_str}\")\n",
    "\n",
    "# Dataset is in Google Drive, accessed via symlink\n",
    "# The symlink points to: DRIVE_ROOT/dataset/MILK10k_Training_Input\n",
    "# But we reference it as: /content/MILK10k/dataset/MILK10k_Training_Input\n",
    "DATASET_ROOT = f'{WORK_DIR}/dataset'\n",
    "\n",
    "print(\"Fixing image paths for Colab environment...\")\n",
    "print(f\"Dataset root: {DATASET_ROOT}\")\n",
    "\n",
    "train_df = fix_image_paths(train_df, DATASET_ROOT)\n",
    "val_df = fix_image_paths(val_df, DATASET_ROOT)\n",
    "\n",
    "print(f\"\\n‚úÖ Image paths updated!\")\n",
    "print(f\"\\nüì∏ Example corrected paths:\")\n",
    "print(f\"  Clinical: {train_df['clinical_image_path'].iloc[0]}\")\n",
    "print(f\"  Dermoscopic: {train_df['dermoscopic_image_path'].iloc[0]}\")\n",
    "\n",
    "# Save corrected CSV files for future use\n",
    "print(f\"\\nüíæ Saving corrected CSV files...\")\n",
    "train_df.to_csv('preprocessed_data/train_data.csv', index=False)\n",
    "val_df.to_csv('preprocessed_data/val_data.csv', index=False)\n",
    "print(f\"‚úÖ Saved corrected CSVs to preprocessed_data/\")\n",
    "\n",
    "# Also save to Google Drive for persistence\n",
    "os.makedirs(f'{DRIVE_ROOT}/preprocessed_data', exist_ok=True)\n",
    "train_df.to_csv(f'{DRIVE_ROOT}/preprocessed_data/train_data.csv', index=False)\n",
    "val_df.to_csv(f'{DRIVE_ROOT}/preprocessed_data/val_data.csv', index=False)\n",
    "print(f\"‚úÖ Saved corrected CSVs to Google Drive for future use\")\n",
    "\n",
    "# Verify paths exist\n",
    "sample_clinical = train_df['clinical_image_path'].iloc[0]\n",
    "sample_dermoscopic = train_df['dermoscopic_image_path'].iloc[0]\n",
    "\n",
    "print(f\"\\nüîç Verifying image files...\")\n",
    "if os.path.exists(sample_clinical):\n",
    "    print(f\"‚úÖ Sample clinical image exists!\")\n",
    "    print(f\"   Path: {sample_clinical}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è WARNING: Clinical image not found at: {sample_clinical}\")\n",
    "    # Try to diagnose the issue\n",
    "    print(f\"\\nüîß Debugging:\")\n",
    "    print(f\"  - WORK_DIR: {WORK_DIR}\")\n",
    "    symlink_path = f'{WORK_DIR}/dataset/MILK10k_Training_Input'\n",
    "    if os.path.islink(symlink_path):\n",
    "        print(f\"  - Dataset symlink target: {os.readlink(symlink_path)}\")\n",
    "    else:\n",
    "        print(f\"  - Not a symlink, checking directory: {os.path.exists(symlink_path)}\")\n",
    "    \n",
    "    # Check lesion directory\n",
    "    lesion_id = sample_clinical.split('/')[-2]\n",
    "    lesion_dir = f'{WORK_DIR}/dataset/MILK10k_Training_Input/{lesion_id}'\n",
    "    print(f\"  - Lesion directory exists: {os.path.exists(lesion_dir)}\")\n",
    "    if os.path.exists(lesion_dir):\n",
    "        print(f\"  - Files in lesion dir: {os.listdir(lesion_dir)}\")\n",
    "    \n",
    "if os.path.exists(sample_dermoscopic):\n",
    "    print(f\"‚úÖ Sample dermoscopic image exists!\")\n",
    "    print(f\"   Path: {sample_dermoscopic}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è WARNING: Dermoscopic image not found at: {sample_dermoscopic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdd3cca",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Create DataLoaders\n",
    "\n",
    "Create training and validation dataloaders with augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a1ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust batch size and workers for Colab Pro with A100\n",
    "BATCH_SIZE = 32  # Increase for A100 (reduce to 16 or 8 if OOM)\n",
    "NUM_WORKERS = 4  # A100 instance has more CPU cores\n",
    "\n",
    "print(f\"Creating dataloaders...\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Num workers: {NUM_WORKERS}\")\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader, val_loader = get_dataloaders(\n",
    "    train_df,\n",
    "    val_df,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    image_size=IMAGE_CONFIG['image_size'],\n",
    "    fusion_strategy=IMAGE_CONFIG['fusion_strategy'],\n",
    "    use_metadata=MODEL_CONFIG['use_metadata']\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Train DataLoader: {len(train_loader)} batches\")\n",
    "print(f\"‚úÖ Val DataLoader: {len(val_loader)} batches\")\n",
    "\n",
    "# Test dataloader\n",
    "print(f\"\\nTesting dataloader...\")\n",
    "for batch in train_loader:\n",
    "    if len(batch) == 3:\n",
    "        images, labels, metadata = batch\n",
    "        print(f\"  Images shape: {images.shape}\")\n",
    "        print(f\"  Labels shape: {labels.shape}\")\n",
    "        print(f\"  Metadata shape: {metadata.shape}\")\n",
    "    else:\n",
    "        images, labels = batch\n",
    "        print(f\"  Images shape: {images.shape}\")\n",
    "        print(f\"  Labels shape: {labels.shape}\")\n",
    "    break\n",
    "print(\"‚úÖ DataLoader test successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603628d7",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Create Model\n",
    "\n",
    "Initialize EfficientNet-B3 model with metadata fusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3a3642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get device\n",
    "device = get_device()\n",
    "\n",
    "# Create model\n",
    "print(\"Creating model...\")\n",
    "model = create_model(\n",
    "    architecture=MODEL_CONFIG['architecture'],\n",
    "    num_classes=len(DIAGNOSIS_CATEGORIES),\n",
    "    pretrained=MODEL_CONFIG['pretrained'],\n",
    "    fusion_strategy=IMAGE_CONFIG['fusion_strategy'],\n",
    "    use_metadata=MODEL_CONFIG['use_metadata'],\n",
    "    metadata_dim=MODEL_CONFIG['metadata_dim'],\n",
    "    dropout=MODEL_CONFIG['dropout']\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params, trainable_params = count_parameters(model)\n",
    "\n",
    "print(f\"\\n‚úÖ Model: {MODEL_CONFIG['architecture']}\")\n",
    "print(f\"‚úÖ Fusion: {IMAGE_CONFIG['fusion_strategy']}\")\n",
    "print(f\"‚úÖ Metadata: {MODEL_CONFIG['use_metadata']}\")\n",
    "print(f\"‚úÖ Device: {device}\")\n",
    "print(f\"‚úÖ Parameters: {total_params:,} (Trainable: {trainable_params:,})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74783846",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Initialize Training Components\n",
    "\n",
    "Setup loss function, optimizer, scheduler, and trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab4aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import Trainer\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "set_seed(TRAIN_CONFIG['random_seed'])\n",
    "\n",
    "# Update checkpoint and log directories to save in Google Drive\n",
    "TRAIN_CONFIG['checkpoint_dir'] = f'{DRIVE_ROOT}/models'\n",
    "TRAIN_CONFIG['log_dir'] = f'{DRIVE_ROOT}/logs'\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(TRAIN_CONFIG['checkpoint_dir'], exist_ok=True)\n",
    "os.makedirs(TRAIN_CONFIG['log_dir'], exist_ok=True)\n",
    "\n",
    "print(f\"Creating trainer...\")\n",
    "print(f\"  Checkpoint dir: {TRAIN_CONFIG['checkpoint_dir']}\")\n",
    "print(f\"  Log dir: {TRAIN_CONFIG['log_dir']}\")\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    class_weights=class_weights,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Trainer initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69ee148",
   "metadata": {},
   "source": [
    "## üîü Load TensorBoard (Optional)\n",
    "\n",
    "Load TensorBoard extension to monitor training in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8d3e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Start TensorBoard (will update during training)\n",
    "%tensorboard --logdir {TRAIN_CONFIG['log_dir']}\n",
    "\n",
    "print(\"‚úÖ TensorBoard loaded! View metrics above during training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce0e8f4",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Start Training üöÄ\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANT**: This will take several hours. Colab free tier may disconnect after ~12 hours.\n",
    "\n",
    "Expected training time on Colab:\n",
    "- **T4 GPU**: ~15-20 hours for 100 epochs\n",
    "- **A100 GPU** (Colab Pro): ~5-8 hours\n",
    "\n",
    "The training will:\n",
    "- Save best model to Google Drive automatically\n",
    "- Save checkpoints every 5 epochs\n",
    "- Stop early if no improvement for 15 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cc7073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"üöÄ Starting training...\")\n",
    "print(\"‚ö†Ô∏è This will take several hours. Don't close the browser tab!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train the model\n",
    "history = trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ TRAINING COMPLETED!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491496b0",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ View Training Results\n",
    "\n",
    "Analyze training history and visualize performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc262381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load training history\n",
    "history_df = pd.read_csv(f'{TRAIN_CONFIG[\"checkpoint_dir\"]}/training_history.csv')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal epochs: {len(history_df)}\")\n",
    "print(f\"Best Macro F1: {history_df['val_f1_macro'].max():.4f}\")\n",
    "print(f\"Best Micro F1: {history_df['val_f1_micro'].max():.4f}\")\n",
    "print(f\"Final Train Loss: {history_df['train_loss'].iloc[-1]:.4f}\")\n",
    "print(f\"Final Val Loss: {history_df['val_loss'].iloc[-1]:.4f}\")\n",
    "\n",
    "# Plot training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss curves\n",
    "axes[0, 0].plot(history_df['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0, 0].plot(history_df['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training and Validation Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# F1 scores\n",
    "axes[0, 1].plot(history_df['val_f1_macro'], label='Macro F1', linewidth=2)\n",
    "axes[0, 1].plot(history_df['val_f1_micro'], label='Micro F1', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('F1 Score')\n",
    "axes[0, 1].set_title('Validation F1 Scores')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate\n",
    "axes[1, 0].plot(history_df['learning_rate'], linewidth=2, color='green')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Learning Rate')\n",
    "axes[1, 0].set_title('Learning Rate Schedule')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss comparison\n",
    "best_epoch = history_df['val_f1_macro'].idxmax()\n",
    "axes[1, 1].bar(['Train Loss', 'Val Loss'], \n",
    "               [history_df.loc[best_epoch, 'train_loss'], \n",
    "                history_df.loc[best_epoch, 'val_loss']])\n",
    "axes[1, 1].set_title(f'Loss at Best Epoch ({best_epoch+1})')\n",
    "axes[1, 1].set_ylabel('Loss')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{DRIVE_ROOT}/training_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Training curves saved to: {DRIVE_ROOT}/training_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23647625",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£3Ô∏è‚É£ Save Model Info\n",
    "\n",
    "Document training results for team reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9759846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Create model info file\n",
    "best_epoch = history_df['val_f1_macro'].idxmax()\n",
    "best_macro_f1 = history_df['val_f1_macro'].max()\n",
    "best_micro_f1 = history_df.loc[best_epoch, 'val_f1_micro']\n",
    "\n",
    "model_info = f\"\"\"# Training Results\n",
    "\n",
    "**Date**: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
    "**GPU**: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\n",
    "**Training Time**: Check notebook execution time\n",
    "**Total Epochs**: {len(history_df)}\n",
    "**Best Epoch**: {best_epoch + 1}\n",
    "**Best Macro F1**: {best_macro_f1:.4f}\n",
    "**Best Micro F1**: {best_micro_f1:.4f}\n",
    "\n",
    "## Model Configuration\n",
    "- Architecture: {MODEL_CONFIG['architecture']}\n",
    "- Fusion Strategy: {IMAGE_CONFIG['fusion_strategy']}\n",
    "- Use Metadata: {MODEL_CONFIG['use_metadata']}\n",
    "- Image Size: {IMAGE_CONFIG['image_size']}\n",
    "- Batch Size: {BATCH_SIZE}\n",
    "\n",
    "## Files\n",
    "- Best Model: `{TRAIN_CONFIG['checkpoint_dir']}/best_model.pth`\n",
    "- Training History: `{TRAIN_CONFIG['checkpoint_dir']}/training_history.csv`\n",
    "- Training Curves: `{DRIVE_ROOT}/training_curves.png`\n",
    "\n",
    "## Next Steps\n",
    "1. Download best_model.pth from Google Drive\n",
    "2. Run inference on test set\n",
    "3. Generate submission file\n",
    "4. Share results with team\n",
    "\"\"\"\n",
    "\n",
    "# Save model info\n",
    "info_path = f'{DRIVE_ROOT}/MODEL_INFO.md'\n",
    "with open(info_path, 'w') as f:\n",
    "    f.write(model_info)\n",
    "\n",
    "print(model_info)\n",
    "print(f\"\\n‚úÖ Model info saved to: {info_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ed94af",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£4Ô∏è‚É£ Download Trained Model\n",
    "\n",
    "Download the trained model and results to your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ee4099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Option 1: Download directly (may be slow for large files)\n",
    "print(\"Downloading files...\")\n",
    "print(\"‚ö†Ô∏è This may take a while for large model files\")\n",
    "\n",
    "# Download best model\n",
    "try:\n",
    "    files.download(f'{TRAIN_CONFIG[\"checkpoint_dir\"]}/best_model.pth')\n",
    "    print(\"‚úÖ Downloaded: best_model.pth\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not download model: {e}\")\n",
    "    print(f\"üìÅ Access it in Google Drive: {TRAIN_CONFIG['checkpoint_dir']}/best_model.pth\")\n",
    "\n",
    "# Download training history\n",
    "try:\n",
    "    files.download(f'{TRAIN_CONFIG[\"checkpoint_dir\"]}/training_history.csv')\n",
    "    print(\"‚úÖ Downloaded: training_history.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not download history: {e}\")\n",
    "\n",
    "# Download training curves\n",
    "try:\n",
    "    files.download(f'{DRIVE_ROOT}/training_curves.png')\n",
    "    print(\"‚úÖ Downloaded: training_curves.png\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not download curves: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üì¶ All files are also saved in Google Drive:\")\n",
    "print(f\"  üìÅ {DRIVE_ROOT}/\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6141ca3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Training Complete!\n",
    "\n",
    "### What to do next:\n",
    "\n",
    "1. **Download the trained model** from Google Drive (`best_model.pth`)\n",
    "2. **Share with your team** via Drive link or upload to repository\n",
    "3. **Run inference** on test set using `src/inference.py` or `src/generate_submission.py`\n",
    "4. **Document results** in README and team chat\n",
    "\n",
    "### Tips for Colab Training:\n",
    "\n",
    "- **Runtime disconnections**: Colab free tier may disconnect after ~12 hours. Use Colab Pro for longer sessions.\n",
    "- **Checkpoints**: Models are saved every 5 epochs to Google Drive, so you can resume if disconnected.\n",
    "- **GPU memory**: If you get OOM errors, reduce `BATCH_SIZE` to 8 or `IMAGE_CONFIG['image_size']` to 224.\n",
    "- **Cost**: Colab Pro (~$10/month) gives faster GPUs (A100) and longer runtime.\n",
    "\n",
    "### Resume Training (if interrupted):\n",
    "\n",
    "```python\n",
    "# Load checkpoint and continue training\n",
    "checkpoint_path = f'{TRAIN_CONFIG[\"checkpoint_dir\"]}/checkpoint_epoch_XX.pth'\n",
    "checkpoint = load_checkpoint(model, optimizer, checkpoint_path, device=device)\n",
    "# Then run trainer.train() again\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Training! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boxmot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
