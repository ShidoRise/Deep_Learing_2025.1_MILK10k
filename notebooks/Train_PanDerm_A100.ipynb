{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU1LJt5Hnv-B"
      },
      "source": [
        "# üß¨ PanDerm Tri-Modal Fusion - Training on Google Colab A100\n",
        "\n",
        "This notebook trains the **Tri-Modal PanDerm Fusion** model for skin lesion classification using the MILK10k dataset on Google Colab with A100 GPU.\n",
        "\n",
        "## üìã Overview\n",
        "\n",
        "- **Model**: Tri-Modal PanDerm Fusion (DermLIP ViT-B/16 dual backbone)\n",
        "- **Architecture**:\n",
        "  - Dual DermLIP encoders (clinical + dermoscopic)\n",
        "  - MONET concept embedding tokens\n",
        "  - Tri-Modal Cross-Attention Transformer (TMCT) fusion blocks with **Stochastic Depth**\n",
        "  - Global context pooling with auxiliary heads\n",
        "- **Dataset**: MILK10k (4,192 train + 1,048 validation)\n",
        "- **Task**: Multi-label classification (11 diagnosis categories)\n",
        "- **Loss**: Compound Loss (Focal + Soft F1) with **Label Smoothing**\n",
        "- **Training**: Mixed precision (bf16) + Layer-wise LR decay + **EMA**\n",
        "- **GPU**: Optimized for A100 40GB\n",
        "\n",
        "## ‚ú® Enhanced Training Features (v2)\n",
        "\n",
        "- **Regularization**: Dropout 0.3, DropPath 0.1, Attention Dropout 0.1\n",
        "- **Augmentation**: Mixup (Œ±=0.8), CutMix (Œ±=1.0), Enhanced CoarseDropout\n",
        "- **EMA**: Exponential Moving Average with warmup for better generalization\n",
        "- **Scheduler**: CosineAnnealingWarmRestarts (T_0=10, T_mult=2) with 5-epoch warmup\n",
        "- **Loss**: Label smoothing 0.1, adjusted weights (focal=0.4, soft_f1=0.6)\n",
        "- **Patience**: Early stopping after 20 epochs without improvement\n",
        "\n",
        "## üöÄ Before Running\n",
        "\n",
        "1. **Set Runtime to GPU**: Runtime ‚Üí Change runtime type ‚Üí GPU (A100 recommended)\n",
        "2. **Upload to Google Drive**:\n",
        "   - `preprocessed_data/` folder (train_data.csv, val_data.csv, class_weights.json)\n",
        "   - `src/` folder (all Python source files)\n",
        "   - Dataset images (MILK10k_Training_Input/)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrpOzPlAnv-D"
      },
      "source": [
        "## 1Ô∏è‚É£ Setup Google Colab Environment\n",
        "\n",
        "Check GPU availability and system specifications.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhAZcPArnv-E",
        "outputId": "6c0e5863-d7fe-452e-f7d2-125ac2e5f30b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Dec 10 12:55:58 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0             52W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "               total        used        free      shared  buff/cache   available\n",
            "Mem:            83Gi       1.0Gi        78Gi       1.0Mi       3.6Gi        81Gi\n",
            "Swap:             0B          0B          0B\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi\n",
        "\n",
        "# Check CUDA version\n",
        "!nvcc --version\n",
        "\n",
        "# Check disk space\n",
        "!df -h | grep -E 'Filesystem|/content'\n",
        "\n",
        "# Check RAM\n",
        "!free -h\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1isKfvzGnv-E"
      },
      "source": [
        "## 2Ô∏è‚É£ Mount Google Drive\n",
        "\n",
        "Mount Google Drive to access datasets and save results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GERzr4Bdnv-E",
        "outputId": "851ad78e-cb4e-4f7a-fb92-8dfe9831427a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Google Drive mounted!\n",
            "üìÅ Project root: /content/drive/MyDrive/MILK10k_Project\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set up project paths (adjust these to match your Google Drive structure)\n",
        "import os\n",
        "DRIVE_ROOT = '/content/drive/MyDrive/MILK10k_Project'\n",
        "os.makedirs(DRIVE_ROOT, exist_ok=True)\n",
        "\n",
        "print(f\"‚úÖ Google Drive mounted!\")\n",
        "print(f\"üìÅ Project root: {DRIVE_ROOT}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncF00QfPnv-F"
      },
      "source": [
        "## 3Ô∏è‚É£ Install Dependencies\n",
        "\n",
        "Install PyTorch with CUDA support, OpenCLIP for DermLIP, and other required packages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDwPfSwonv-F",
        "outputId": "64eee9c8-137e-4177-eeec-7b61983ad0f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/44.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚úÖ PyTorch: 2.9.0+cu126\n",
            "‚úÖ TorchVision: 0.24.0+cu126\n",
            "‚úÖ Timm: 1.0.22\n",
            "‚úÖ Albumentations: 2.0.8\n",
            "‚úÖ OpenCLIP: 3.2.0\n",
            "‚úÖ CUDA Available: True\n",
            "‚úÖ GPU: NVIDIA A100-SXM4-40GB\n",
            "‚úÖ CUDA Version: 12.6\n",
            "‚úÖ GPU Memory: 42.5 GB\n"
          ]
        }
      ],
      "source": [
        "# Install required packages for PanDerm\n",
        "!pip install -q timm albumentations tensorboard scikit-learn\n",
        "!pip install -q open_clip_torch  # For DermLIP encoder\n",
        "\n",
        "# Verify installations\n",
        "import torch\n",
        "import torchvision\n",
        "import timm\n",
        "import albumentations as A\n",
        "\n",
        "print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
        "print(f\"‚úÖ TorchVision: {torchvision.__version__}\")\n",
        "print(f\"‚úÖ Timm: {timm.__version__}\")\n",
        "print(f\"‚úÖ Albumentations: {A.__version__}\")\n",
        "\n",
        "# Check OpenCLIP\n",
        "try:\n",
        "    import open_clip\n",
        "    print(f\"‚úÖ OpenCLIP: {open_clip.__version__}\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è OpenCLIP not installed. Will use timm fallback.\")\n",
        "\n",
        "print(f\"‚úÖ CUDA Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"‚úÖ CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"‚úÖ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E37gCzJhnv-G"
      },
      "source": [
        "## 4Ô∏è‚É£ Setup Project Files\n",
        "\n",
        "Copy project files from Google Drive to Colab workspace.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPSYm8Vbnv-G",
        "outputId": "bd2bfb3d-617d-4299-85c2-e1e5b356d030"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/MILK10k_PanDerm\n",
            "‚úÖ Copied src/ from Google Drive\n",
            "‚úÖ Copied preprocessed_data/ from Google Drive\n",
            "‚úÖ Linked dataset from Google Drive (no copy needed)\n",
            "\n",
            "üìÅ Working directory: /content/MILK10k_PanDerm\n",
            "üìÇ Contents:\n",
            "total 32\n",
            "drwxr-xr-x 8 root root 4096 Dec 10 12:57 .\n",
            "drwxr-xr-x 1 root root 4096 Dec 10 12:56 ..\n",
            "drwxr-xr-x 2 root root 4096 Dec 10 12:57 dataset\n",
            "drwxr-xr-x 2 root root 4096 Dec 10 12:57 logs\n",
            "drwxr-xr-x 2 root root 4096 Dec 10 12:57 models\n",
            "drwx------ 2 root root 4096 Dec  3 08:28 preprocessed_data\n",
            "drwxr-xr-x 2 root root 4096 Dec 10 12:57 results\n",
            "drwx------ 3 root root 4096 Dec 10 09:41 src\n",
            "\n",
            "üì∏ Dataset path: /content/MILK10k_PanDerm/dataset/MILK10k_Training_Input\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Create working directory\n",
        "WORK_DIR = '/content/MILK10k_PanDerm'\n",
        "os.makedirs(WORK_DIR, exist_ok=True)\n",
        "%cd {WORK_DIR}\n",
        "\n",
        "# Copy source code from Drive\n",
        "SRC_DRIVE = f'{DRIVE_ROOT}/src'\n",
        "if os.path.exists(SRC_DRIVE):\n",
        "    if os.path.exists(f'{WORK_DIR}/src'):\n",
        "        shutil.rmtree(f'{WORK_DIR}/src')\n",
        "    shutil.copytree(SRC_DRIVE, f'{WORK_DIR}/src')\n",
        "    print(\"‚úÖ Copied src/ from Google Drive\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è src/ not found in Google Drive. Please upload it first!\")\n",
        "    print(f\"   Expected path: {SRC_DRIVE}\")\n",
        "\n",
        "# Copy preprocessed data\n",
        "PREPROCESSED_DRIVE = f'{DRIVE_ROOT}/preprocessed_data'\n",
        "if os.path.exists(PREPROCESSED_DRIVE):\n",
        "    if os.path.exists(f'{WORK_DIR}/preprocessed_data'):\n",
        "        shutil.rmtree(f'{WORK_DIR}/preprocessed_data')\n",
        "    shutil.copytree(PREPROCESSED_DRIVE, f'{WORK_DIR}/preprocessed_data')\n",
        "    print(\"‚úÖ Copied preprocessed_data/ from Google Drive\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è preprocessed_data/ not found. Please upload it first!\")\n",
        "    print(f\"   Expected path: {PREPROCESSED_DRIVE}\")\n",
        "\n",
        "# Use dataset directly from Google Drive (symlink to avoid copying large files)\n",
        "DATASET_DRIVE = f'{DRIVE_ROOT}/dataset/MILK10k_Training_Input'\n",
        "if os.path.exists(DATASET_DRIVE):\n",
        "    os.makedirs(f'{WORK_DIR}/dataset', exist_ok=True)\n",
        "    symlink_path = f'{WORK_DIR}/dataset/MILK10k_Training_Input'\n",
        "    if os.path.islink(symlink_path) or os.path.exists(symlink_path):\n",
        "        os.remove(symlink_path) if os.path.islink(symlink_path) else shutil.rmtree(symlink_path)\n",
        "    os.symlink(DATASET_DRIVE, symlink_path)\n",
        "    print(f\"‚úÖ Linked dataset from Google Drive (no copy needed)\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Dataset not found at: {DATASET_DRIVE}\")\n",
        "    print(\"   Please upload MILK10k_Training_Input/ to your Google Drive!\")\n",
        "\n",
        "# Create necessary directories\n",
        "os.makedirs('models', exist_ok=True)\n",
        "os.makedirs('logs', exist_ok=True)\n",
        "os.makedirs('results', exist_ok=True)\n",
        "\n",
        "print(f\"\\nüìÅ Working directory: {WORK_DIR}\")\n",
        "print(f\"üìÇ Contents:\")\n",
        "!ls -la\n",
        "print(f\"\\nüì∏ Dataset path: {WORK_DIR}/dataset/MILK10k_Training_Input\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zBD5ZKCnv-H"
      },
      "source": [
        "## 5Ô∏è‚É£ Load Configuration\n",
        "\n",
        "Import PanDerm configuration and verify settings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOE44OQFnv-H",
        "outputId": "f933fd4f-d2d7-4e07-8d5d-d66407c15032"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "PANDERM TRAINING CONFIGURATION\n",
            "============================================================\n",
            "\n",
            "üß¨ Model Config:\n",
            "  model_name: redlessone/DermLIP_PanDerm-base-w-PubMed-256\n",
            "  embed_dim: 768\n",
            "  num_heads: 8\n",
            "  num_classes: 11\n",
            "  dropout: 0.1\n",
            "  freeze_clinical: 6\n",
            "  freeze_dermoscopic: 4\n",
            "  num_concept_tokens: 11\n",
            "  concept_hidden_dim: 256\n",
            "  tmct_num_layers: 2\n",
            "  mlp_ratio: 4.0\n",
            "  use_auxiliary_heads: True\n",
            "  aux_loss_weight: 0.3\n",
            "\n",
            "üéØ Training Config:\n",
            "  batch_size: 32\n",
            "  num_epochs: 60\n",
            "  gradient_accumulation: 2\n",
            "  base_lr: 0.0001\n",
            "  backbone_lr_decay: 0.9\n",
            "  min_lr: 1e-07\n",
            "  weight_decay: 0.05\n",
            "  scheduler: cosine_warmup\n",
            "  warmup_epochs: 3\n",
            "  early_stopping_patience: 12\n",
            "  gradient_clip: 1.0\n",
            "  mixed_precision: bf16\n",
            "  modality_dropout: 0.2\n",
            "  concept_dropout: 0.1\n",
            "  random_seed: 42\n",
            "  num_workers: 8\n",
            "  save_every: 5\n",
            "  checkpoint_dir: /content/MILK10k_PanDerm/models\n",
            "  log_dir: /content/MILK10k_PanDerm/logs\n",
            "  use_ema: True\n",
            "  ema_decay: 0.9999\n",
            "\n",
            "üñºÔ∏è Image Config:\n",
            "  image_size: 224\n",
            "  normalize_mean: [0.48145466, 0.4578275, 0.40821073]\n",
            "  normalize_std: [0.26862954, 0.26130258, 0.27577711]\n",
            "\n",
            "‚öñÔ∏è Loss Config:\n",
            "  type: compound\n",
            "  focal_gamma: 2.0\n",
            "  focal_weight: 0.5\n",
            "  soft_f1_weight: 0.5\n",
            "  use_class_weights: True\n",
            "  aux_loss_weight: 0.3\n",
            "\n",
            "üìÇ Diagnosis Categories (11):\n",
            "  - AKIEC\n",
            "  - BCC\n",
            "  - BEN_OTH\n",
            "  - BKL\n",
            "  - DF\n",
            "  - INF\n",
            "  - MAL_OTH\n",
            "  - MEL\n",
            "  - NV\n",
            "  - SCCKA\n",
            "  - VASC\n",
            "\n",
            "üî¨ MONET Features (7):\n",
            "  - MONET_ulceration_crust\n",
            "  - MONET_hair\n",
            "  - MONET_vasculature_vessels\n",
            "  - MONET_erythema\n",
            "  - MONET_pigmented\n",
            "  - MONET_gel_water_drop_fluid_dermoscopy_liquid\n",
            "  - MONET_skin_markings_pen_ink_purple_pen\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, f'{WORK_DIR}/src')\n",
        "\n",
        "# Import PanDerm specific modules\n",
        "from config import (\n",
        "    MODEL_CONFIG_PANDERM, IMAGE_CONFIG_PANDERM, TRAIN_CONFIG_PANDERM,\n",
        "    LOSS_CONFIG_PANDERM, DIAGNOSIS_CATEGORIES, MONET_FEATURES\n",
        ")\n",
        "from utils import set_seed, get_device, count_parameters, save_checkpoint\n",
        "\n",
        "# Display PanDerm configuration\n",
        "print(\"=\" * 60)\n",
        "print(\"PANDERM TRAINING CONFIGURATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nüß¨ Model Config:\")\n",
        "for key, value in MODEL_CONFIG_PANDERM.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(f\"\\nüéØ Training Config:\")\n",
        "for key, value in TRAIN_CONFIG_PANDERM.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(f\"\\nüñºÔ∏è Image Config:\")\n",
        "for key, value in IMAGE_CONFIG_PANDERM.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(f\"\\n‚öñÔ∏è Loss Config:\")\n",
        "for key, value in LOSS_CONFIG_PANDERM.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(f\"\\nüìÇ Diagnosis Categories ({len(DIAGNOSIS_CATEGORIES)}):\")\n",
        "for cat in DIAGNOSIS_CATEGORIES:\n",
        "    print(f\"  - {cat}\")\n",
        "\n",
        "print(f\"\\nüî¨ MONET Features ({len(MONET_FEATURES)}):\")\n",
        "for feat in MONET_FEATURES:\n",
        "    print(f\"  - {feat}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqNeASRVnv-H"
      },
      "source": [
        "## 6Ô∏è‚É£ Load Dataset\n",
        "\n",
        "Load preprocessed training and validation data with MONET features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjO4HiS-nv-H",
        "outputId": "fcd7d4c9-cdb2-4c46-b86a-030e83dfe669"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading preprocessed data...\n",
            "‚úÖ Training samples: 4,192\n",
            "‚úÖ Validation samples: 1,048\n",
            "\n",
            "üî¨ MONET columns found: 14\n",
            "  - clinical_MONET_ulceration_crust\n",
            "  - clinical_MONET_hair\n",
            "  - clinical_MONET_vasculature_vessels\n",
            "  - clinical_MONET_erythema\n",
            "  - clinical_MONET_pigmented\n",
            "  - clinical_MONET_gel_water_drop_fluid_dermoscopy_liquid\n",
            "  - clinical_MONET_skin_markings_pen_ink_purple_pen\n",
            "\n",
            "‚öñÔ∏è Class Weights loaded\n",
            "\n",
            "üìà Label Distribution (Training):\n",
            "  AKIEC: 242 (5.77%)\n",
            "  BCC: 2,018 (48.14%)\n",
            "  BEN_OTH: 35 (0.83%)\n",
            "  BKL: 435 (10.38%)\n",
            "  DF: 42 (1.00%)\n",
            "  INF: 40 (0.95%)\n",
            "  MAL_OTH: 7 (0.17%)\n",
            "  MEL: 360 (8.59%)\n",
            "  NV: 597 (14.24%)\n",
            "  SCCKA: 378 (9.02%)\n",
            "  VASC: 38 (0.91%)\n",
            "\n",
            "üìä Sample columns:\n",
            "['lesion_id', 'AKIEC', 'BCC', 'BEN_OTH', 'BKL', 'DF', 'INF', 'MAL_OTH', 'MEL', 'NV', 'SCCKA', 'VASC', 'age_approx', 'sex', 'skin_tone_class', 'site', 'clinical_isic_id', 'clinical_MONET_ulceration_crust', 'clinical_MONET_hair', 'clinical_MONET_vasculature_vessels']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# Load preprocessed data\n",
        "print(\"Loading preprocessed data...\")\n",
        "train_df = pd.read_csv('preprocessed_data/train_data.csv')\n",
        "val_df = pd.read_csv('preprocessed_data/val_data.csv')\n",
        "\n",
        "print(f\"‚úÖ Training samples: {len(train_df):,}\")\n",
        "print(f\"‚úÖ Validation samples: {len(val_df):,}\")\n",
        "\n",
        "# Check for MONET features\n",
        "monet_cols = [col for col in train_df.columns if 'MONET_' in col]\n",
        "print(f\"\\nüî¨ MONET columns found: {len(monet_cols)}\")\n",
        "for col in monet_cols[:7]:  # Show first 7\n",
        "    print(f\"  - {col}\")\n",
        "\n",
        "# Load class weights\n",
        "try:\n",
        "    with open('preprocessed_data/class_weights.json', 'r') as f:\n",
        "        class_weights = json.load(f)\n",
        "    print(f\"\\n‚öñÔ∏è Class Weights loaded\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"\\n‚ö†Ô∏è class_weights.json not found, will compute from data\")\n",
        "    class_weights = None\n",
        "\n",
        "# Compute samples per class for class-balanced loss\n",
        "print(f\"\\nüìà Label Distribution (Training):\")\n",
        "samples_per_class = []\n",
        "for cat in DIAGNOSIS_CATEGORIES:\n",
        "    if cat in train_df.columns:\n",
        "        count = int(train_df[cat].sum())\n",
        "        samples_per_class.append(count)\n",
        "        pct = (count / len(train_df)) * 100\n",
        "        print(f\"  {cat}: {count:,} ({pct:.2f}%)\")\n",
        "    else:\n",
        "        samples_per_class.append(100)  # Default\n",
        "\n",
        "print(f\"\\nüìä Sample columns:\")\n",
        "print(train_df.columns.tolist()[:20])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb5q4AaYnv-I"
      },
      "source": [
        "### Fix Image Paths for Colab\n",
        "\n",
        "The preprocessed CSV files contain Windows absolute paths. We need to fix them for Colab's Linux environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgBaqXHznv-I",
        "outputId": "e11ce017-d78e-42a8-bbe0-a1f976c694b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fixing image paths for Colab environment...\n",
            "Dataset root: /content/MILK10k_PanDerm/dataset\n",
            "\n",
            "‚úÖ Image paths updated!\n",
            "\n",
            "üì∏ Example corrected paths:\n",
            "  Clinical: /content/MILK10k_PanDerm/dataset/MILK10k_Training_Input/IL_8583674/ISIC_8570261.jpg\n",
            "  Dermoscopic: /content/MILK10k_PanDerm/dataset/MILK10k_Training_Input/IL_8583674/ISIC_7454892.jpg\n",
            "\n",
            "üíæ Saving corrected CSV files...\n",
            "‚úÖ Saved corrected CSVs to preprocessed_data/\n",
            "‚úÖ Saved corrected CSVs to Google Drive\n",
            "\n",
            "üîç Verifying image files...\n",
            "‚úÖ Sample clinical image exists!\n",
            "‚úÖ Sample dermoscopic image exists!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "def fix_image_paths(df, dataset_root):\n",
        "    \"\"\"\n",
        "    Fix Windows absolute paths to work with Colab's dataset location.\n",
        "\n",
        "    Extracts only the relative path (lesion_id/image.jpg) and reconstructs\n",
        "    with the correct dataset root path.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    for col in ['clinical_image_path', 'dermoscopic_image_path']:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].apply(lambda x: extract_relative_path(str(x), dataset_root))\n",
        "\n",
        "    return df\n",
        "\n",
        "def extract_relative_path(path_str, dataset_root):\n",
        "    \"\"\"Extract lesion_id/image.jpg from any path format (Windows or Linux).\"\"\"\n",
        "    # Use regex to extract the lesion_id and image filename\n",
        "    match = re.search(r'(IL_\\d+)[/\\\\](ISIC_\\d+\\.jpg)', path_str)\n",
        "\n",
        "    if match:\n",
        "        lesion_id = match.group(1)\n",
        "        image_file = match.group(2)\n",
        "        return os.path.join(dataset_root, 'MILK10k_Training_Input', lesion_id, image_file)\n",
        "    else:\n",
        "        # Fallback: extract last 2 parts\n",
        "        parts = re.split(r'[/\\\\]', path_str)\n",
        "        parts = [p for p in parts if p]\n",
        "        if len(parts) >= 2:\n",
        "            return os.path.join(dataset_root, 'MILK10k_Training_Input', parts[-2], parts[-1])\n",
        "        else:\n",
        "            raise ValueError(f\"Cannot extract lesion_id and image from path: {path_str}\")\n",
        "\n",
        "# Dataset root in Colab\n",
        "DATASET_ROOT = f'{WORK_DIR}/dataset'\n",
        "\n",
        "print(\"Fixing image paths for Colab environment...\")\n",
        "print(f\"Dataset root: {DATASET_ROOT}\")\n",
        "\n",
        "train_df = fix_image_paths(train_df, DATASET_ROOT)\n",
        "val_df = fix_image_paths(val_df, DATASET_ROOT)\n",
        "\n",
        "print(f\"\\n‚úÖ Image paths updated!\")\n",
        "print(f\"\\nüì∏ Example corrected paths:\")\n",
        "print(f\"  Clinical: {train_df['clinical_image_path'].iloc[0]}\")\n",
        "print(f\"  Dermoscopic: {train_df['dermoscopic_image_path'].iloc[0]}\")\n",
        "\n",
        "# Save corrected CSV files\n",
        "print(f\"\\nüíæ Saving corrected CSV files...\")\n",
        "train_df.to_csv('preprocessed_data/train_data.csv', index=False)\n",
        "val_df.to_csv('preprocessed_data/val_data.csv', index=False)\n",
        "print(f\"‚úÖ Saved corrected CSVs to preprocessed_data/\")\n",
        "\n",
        "# Also save to Google Drive for persistence\n",
        "os.makedirs(f'{DRIVE_ROOT}/preprocessed_data', exist_ok=True)\n",
        "train_df.to_csv(f'{DRIVE_ROOT}/preprocessed_data/train_data_colab.csv', index=False)\n",
        "val_df.to_csv(f'{DRIVE_ROOT}/preprocessed_data/val_data_colab.csv', index=False)\n",
        "print(f\"‚úÖ Saved corrected CSVs to Google Drive\")\n",
        "\n",
        "# Verify paths exist\n",
        "sample_clinical = train_df['clinical_image_path'].iloc[0]\n",
        "sample_dermoscopic = train_df['dermoscopic_image_path'].iloc[0]\n",
        "\n",
        "print(f\"\\nüîç Verifying image files...\")\n",
        "if os.path.exists(sample_clinical):\n",
        "    print(f\"‚úÖ Sample clinical image exists!\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è WARNING: Clinical image not found at: {sample_clinical}\")\n",
        "    print(f\"\\nüîß Debugging:\")\n",
        "    symlink_path = f'{WORK_DIR}/dataset/MILK10k_Training_Input'\n",
        "    if os.path.islink(symlink_path):\n",
        "        print(f\"  - Dataset symlink target: {os.readlink(symlink_path)}\")\n",
        "    else:\n",
        "        print(f\"  - Directory exists: {os.path.exists(symlink_path)}\")\n",
        "\n",
        "if os.path.exists(sample_dermoscopic):\n",
        "    print(f\"‚úÖ Sample dermoscopic image exists!\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è WARNING: Dermoscopic image not found at: {sample_dermoscopic}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4p9xPHNnv-I"
      },
      "source": [
        "## 7Ô∏è‚É£ Create PanDerm DataLoaders\n",
        "\n",
        "Create training and validation dataloaders with PanDerm-specific transforms and MONET features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_62MEoqRnv-I",
        "outputId": "29a4cf04-5e56-41f5-eec2-cc40f86e73d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating PanDerm dataloaders...\n",
            "  Image size: 224\n",
            "  Batch size: 48\n",
            "  Num workers: 8\n",
            "\n",
            "‚úÖ Train DataLoader: 87 batches\n",
            "‚úÖ Val DataLoader: 22 batches\n",
            "\n",
            "üß™ Testing PanDerm dataloader...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "/content/MILK10k_PanDerm/src/train_panderm.py:119: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout\n",
            "  A.CoarseDropout(max_holes=8, max_height=image_size//8, max_width=image_size//8, p=0.3),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Clinical image shape: torch.Size([48, 3, 224, 224])\n",
            "  Dermoscopic image shape: torch.Size([48, 3, 224, 224])\n",
            "  MONET scores shape: torch.Size([48, 7])\n",
            "  Metadata shape: torch.Size([48, 11])\n",
            "  Labels shape: torch.Size([48, 11])\n",
            "\n",
            "‚úÖ DataLoader test successful!\n"
          ]
        }
      ],
      "source": [
        "from train_panderm import PanDermDataset, get_panderm_transforms, get_panderm_dataloaders\n",
        "\n",
        "# Optimized for A100 40GB GPU with PanDerm dual-backbone\n",
        "# PanDerm uses 224x224 images (ViT native resolution)\n",
        "BATCH_SIZE = 48  # Conservative for dual ViT backbones (try 48 for max utilization)\n",
        "NUM_WORKERS = 8  # A100 instances have more CPU cores\n",
        "IMAGE_SIZE = IMAGE_CONFIG_PANDERM['image_size']  # 224\n",
        "\n",
        "print(f\"Creating PanDerm dataloaders...\")\n",
        "print(f\"  Image size: {IMAGE_SIZE}\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  Num workers: {NUM_WORKERS}\")\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader, val_loader = get_panderm_dataloaders(\n",
        "    train_df,\n",
        "    val_df,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    image_size=IMAGE_SIZE\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Train DataLoader: {len(train_loader)} batches\")\n",
        "print(f\"‚úÖ Val DataLoader: {len(val_loader)} batches\")\n",
        "\n",
        "# Test dataloader - PanDerm expects (clinical_img, dermoscopic_img, monet_scores, metadata, labels)\n",
        "print(f\"\\nüß™ Testing PanDerm dataloader...\")\n",
        "for batch in train_loader:\n",
        "    clinical_img, dermoscopic_img, monet_scores, metadata, labels = batch\n",
        "    print(f\"  Clinical image shape: {clinical_img.shape}\")\n",
        "    print(f\"  Dermoscopic image shape: {dermoscopic_img.shape}\")\n",
        "    print(f\"  MONET scores shape: {monet_scores.shape}\")\n",
        "    print(f\"  Metadata shape: {metadata.shape}\")\n",
        "    print(f\"  Labels shape: {labels.shape}\")\n",
        "    break\n",
        "\n",
        "print(\"\\n‚úÖ DataLoader test successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfMRLmWsnv-I"
      },
      "source": [
        "## 8Ô∏è‚É£ Create PanDerm Model\n",
        "\n",
        "Initialize the **Tri-Modal PanDerm Fusion** model with:\n",
        "- Dual DermLIP ViT-B/16 encoders for clinical and dermoscopic images\n",
        "- MONET concept embedding for interpretable features\n",
        "- TMCT (Tri-Modal Cross-attention Transformer) fusion blocks\n",
        "- Global context pooling with auxiliary heads for deep supervision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428,
          "referenced_widgets": [
            "c73f90bdc7d946cfaab485d760d00fe8",
            "624541bfae03409e8a297c529b80261d",
            "99f61d9310f54264ae9b6e9516d34ea6",
            "0b822554d2cc495797cff11095bd093a",
            "2801734acdb1431eaed0899a9ec2f0c9",
            "73ef5519fc0348e9a2a400a6efbb95f0",
            "c6bcbd9608dc4d06975e406a01517b1e",
            "d128986d7be24efd981209985ca64ae7",
            "a8f5b4b58c6c43eb8017da8c3152e054",
            "bfb8915d309e4990b986936592319e49",
            "17881c0e151f4cc6972a88f5cb7264f1",
            "9d28ed34c5654efeb6e00359597b9c63",
            "9961e12d8cdf4c64a172e6497b7f7e1f",
            "97cd603def3741cb9a591d11d9c0ac08",
            "44a7acb7bae7464aa99e3adaf9896d58",
            "dc039cbc06ff41bcb9824bf6423667a4",
            "0562886e558b427aafc9d77127e1f567",
            "c336f53ee5074cd3876588ae29b61864",
            "04a8d5f13cd147f49b41db49f8185aca",
            "742481e32db54d76aa0b3307170a1c11",
            "3ce7b36c0114495d816de194d5dc9553",
            "d6864af1c0e6491b9b8c7d4b9bd7f605",
            "fcf2944d3e87474cb1c2132fa77e83aa",
            "0b1af0b652884dd094a18a867a160ddf",
            "1051480eb31c479c883713c7ccc37e2b",
            "fbf7feeee66342c7b7d12e5d04a5293c",
            "92c7cb8322aa4eecaab50a12f9471c1b",
            "6f84066510a2443abcbb79c1b39ef43e",
            "2ff42906b4ca45a88c7075302b6c6707",
            "fd155f9a58cc441097f1ac6b920b3e10",
            "4217df9bc400404fad2563ba95564ca0",
            "b367dda78211492abffff9d5956fae75",
            "3acf2c2347ce4625b153d2b8075982c5"
          ]
        },
        "id": "c1n4TQ45nv-I",
        "outputId": "fc1ae9a9-0750-45d8-9028-93b6e63b8997"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using GPU: NVIDIA A100-SXM4-40GB\n",
            "Creating Tri-Modal PanDerm Fusion model...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c73f90bdc7d946cfaab485d760d00fe8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "open_clip_config.json:   0%|          | 0.00/638 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d28ed34c5654efeb6e00359597b9c63",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "open_clip_model.safetensors:   0%|          | 0.00/784M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/MILK10k_PanDerm/src/models_panderm.py:74: UserWarning: Failed to load DermLIP from HuggingFace: CLIPVisionCfg.__init__() got an unexpected keyword argument 'pretrain_path'. Falling back to timm ViT.\n",
            "  warnings.warn(f\"Failed to load DermLIP from HuggingFace: {e}. Falling back to timm ViT.\")\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcf2944d3e87474cb1c2132fa77e83aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Model: Tri-Modal PanDerm Fusion\n",
            "‚úÖ Backbone: redlessone/DermLIP_PanDerm-base-w-PubMed-256\n",
            "‚úÖ Embed dim: 768\n",
            "‚úÖ TMCT layers: 2\n",
            "‚úÖ Auxiliary heads: True\n",
            "‚úÖ Device: cuda\n",
            "\n",
            "üìä Parameters:\n",
            "  Total: 203,130,593\n",
            "  Trainable: 130,768,097\n",
            "  Frozen: 72,362,496\n",
            "  Model size: 774.9 MB (FP32)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from models_panderm import create_panderm_model, get_layer_wise_lr_params\n",
        "\n",
        "# Get device\n",
        "device = get_device()\n",
        "\n",
        "# Create PanDerm model\n",
        "print(\"Creating Tri-Modal PanDerm Fusion model...\")\n",
        "model = create_panderm_model(\n",
        "    model_name=MODEL_CONFIG_PANDERM['model_name'],\n",
        "    embed_dim=MODEL_CONFIG_PANDERM['embed_dim'],\n",
        "    num_heads=MODEL_CONFIG_PANDERM['num_heads'],\n",
        "    num_classes=MODEL_CONFIG_PANDERM['num_classes'],\n",
        "    dropout=MODEL_CONFIG_PANDERM['dropout'],\n",
        "    freeze_clinical=MODEL_CONFIG_PANDERM['freeze_clinical'],\n",
        "    freeze_dermoscopic=MODEL_CONFIG_PANDERM['freeze_dermoscopic'],\n",
        "    num_concept_tokens=MODEL_CONFIG_PANDERM['num_concept_tokens'],\n",
        "    tmct_num_layers=MODEL_CONFIG_PANDERM.get('tmct_num_layers', 2),\n",
        "    use_auxiliary_heads=MODEL_CONFIG_PANDERM['use_auxiliary_heads'],\n",
        "    pretrained=True\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "frozen_params = total_params - trainable_params\n",
        "\n",
        "print(f\"\\n‚úÖ Model: Tri-Modal PanDerm Fusion\")\n",
        "print(f\"‚úÖ Backbone: {MODEL_CONFIG_PANDERM['model_name']}\")\n",
        "print(f\"‚úÖ Embed dim: {MODEL_CONFIG_PANDERM['embed_dim']}\")\n",
        "print(f\"‚úÖ TMCT layers: {MODEL_CONFIG_PANDERM.get('tmct_num_layers', 2)}\")\n",
        "print(f\"‚úÖ Auxiliary heads: {MODEL_CONFIG_PANDERM['use_auxiliary_heads']}\")\n",
        "print(f\"‚úÖ Device: {device}\")\n",
        "print(f\"\\nüìä Parameters:\")\n",
        "print(f\"  Total: {total_params:,}\")\n",
        "print(f\"  Trainable: {trainable_params:,}\")\n",
        "print(f\"  Frozen: {frozen_params:,}\")\n",
        "print(f\"  Model size: {total_params * 4 / 1024 / 1024:.1f} MB (FP32)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY23JHJpnv-I"
      },
      "source": [
        "### Test Forward Pass\n",
        "\n",
        "Verify the model works correctly with a sample batch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNONq_Kmnv-J"
      },
      "outputs": [],
      "source": [
        "# Test forward pass with a real batch\n",
        "print(\"Testing forward pass...\")\n",
        "model.eval()\n",
        "\n",
        "for batch in train_loader:\n",
        "    clinical_img, dermoscopic_img, monet_scores, metadata, labels = batch\n",
        "    clinical_img = clinical_img.to(device)\n",
        "    dermoscopic_img = dermoscopic_img.to(device)\n",
        "    monet_scores = monet_scores.to(device)\n",
        "    metadata = metadata.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            outputs = model(clinical_img, dermoscopic_img, monet_scores, metadata)\n",
        "\n",
        "    if isinstance(outputs, dict):\n",
        "        print(f\"‚úÖ Output (dict) - training mode with aux heads:\")\n",
        "        for k, v in outputs.items():\n",
        "            print(f\"   {k}: {v.shape}\")\n",
        "    else:\n",
        "        print(f\"‚úÖ Output shape: {outputs.shape}\")\n",
        "    break\n",
        "\n",
        "# Memory estimation\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "    model.train()\n",
        "    with torch.amp.autocast('cuda'):\n",
        "        outputs = model(clinical_img, dermoscopic_img, monet_scores, metadata)\n",
        "    peak_memory = torch.cuda.max_memory_allocated() / 1024 / 1024 / 1024\n",
        "    print(f\"\\nüíæ Peak GPU memory (batch={BATCH_SIZE}): {peak_memory:.2f} GB\")\n",
        "\n",
        "    # Estimate max batch size\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    estimated_max_batch = int(BATCH_SIZE * (gpu_memory * 0.8) / peak_memory)\n",
        "    print(f\"üìä Estimated max batch size: {estimated_max_batch}\")\n",
        "\n",
        "print(\"\\n‚úÖ Forward pass test completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tT-EJFUqnv-J"
      },
      "source": [
        "## 9Ô∏è‚É£ Initialize Training Components\n",
        "\n",
        "Setup the PanDerm trainer with:\n",
        "- Compound Loss (Focal + Soft F1) with class balancing\n",
        "- Layer-wise learning rate decay\n",
        "- OneCycleLR scheduler with warmup\n",
        "- Mixed precision training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUl3lrzrnv-J"
      },
      "outputs": [],
      "source": [
        "from train_panderm import PanDermTrainer\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "set_seed(TRAIN_CONFIG_PANDERM['random_seed'])\n",
        "\n",
        "# Update checkpoint and log directories to save in Google Drive\n",
        "CHECKPOINT_DIR = f'{DRIVE_ROOT}/models/panderm'\n",
        "LOG_DIR = f'{DRIVE_ROOT}/logs/panderm'\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "# Override config paths\n",
        "TRAIN_CONFIG_PANDERM['checkpoint_dir'] = CHECKPOINT_DIR\n",
        "TRAIN_CONFIG_PANDERM['log_dir'] = LOG_DIR\n",
        "\n",
        "print(f\"Creating PanDerm trainer...\")\n",
        "print(f\"  Checkpoint dir: {CHECKPOINT_DIR}\")\n",
        "print(f\"  Log dir: {LOG_DIR}\")\n",
        "print(f\"  Base LR: {TRAIN_CONFIG_PANDERM['base_lr']}\")\n",
        "print(f\"  Backbone LR decay: {TRAIN_CONFIG_PANDERM['backbone_lr_decay']}\")\n",
        "print(f\"  Gradient accumulation: {TRAIN_CONFIG_PANDERM.get('gradient_accumulation', 1)}\")\n",
        "print(f\"  Mixed precision: {TRAIN_CONFIG_PANDERM.get('mixed_precision', 'fp16')}\")\n",
        "\n",
        "# Create trainer\n",
        "trainer = PanDermTrainer(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    samples_per_class=samples_per_class,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ PanDerm Trainer initialized successfully!\")\n",
        "print(f\"\\nüìà Training setup:\")\n",
        "print(f\"  Epochs: {TRAIN_CONFIG_PANDERM['num_epochs']}\")\n",
        "print(f\"  Early stopping patience: {TRAIN_CONFIG_PANDERM['early_stopping_patience']}\")\n",
        "print(f\"  Warmup epochs: {TRAIN_CONFIG_PANDERM['warmup_epochs']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9IimrL9nv-J"
      },
      "source": [
        "### View Layer-wise Learning Rates\n",
        "\n",
        "PanDerm uses layer-wise learning rate decay for better fine-tuning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7PT7L0Unv-J"
      },
      "outputs": [],
      "source": [
        "# Show layer-wise learning rates\n",
        "print(\"Layer-wise Learning Rates:\")\n",
        "print(\"=\" * 50)\n",
        "lr_params = get_layer_wise_lr_params(\n",
        "    model,\n",
        "    base_lr=TRAIN_CONFIG_PANDERM['base_lr'],\n",
        "    decay_rate=TRAIN_CONFIG_PANDERM['backbone_lr_decay']\n",
        ")\n",
        "\n",
        "for i, group in enumerate(lr_params):\n",
        "    num_params = sum(p.numel() for p in group['params'])\n",
        "    print(f\"  {group['name']}: lr={group['lr']:.2e}, params={num_params:,}\")\n",
        "\n",
        "print(f\"\\nTotal parameter groups: {len(lr_params)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CydTUsv9nv-J"
      },
      "source": [
        "## üîü Load TensorBoard (Optional)\n",
        "\n",
        "Load TensorBoard extension to monitor training in real-time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1uhrnSMnv-J"
      },
      "outputs": [],
      "source": [
        "# Load TensorBoard extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Start TensorBoard (will update during training)\n",
        "%tensorboard --logdir {LOG_DIR}\n",
        "\n",
        "print(\"‚úÖ TensorBoard loaded! View metrics above during training.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GuFpNiFnv-J"
      },
      "source": [
        "## 1Ô∏è‚É£1Ô∏è‚É£ Start Training üöÄ\n",
        "\n",
        "**‚ö†Ô∏è IMPORTANT**: This will take several hours depending on your GPU.\n",
        "\n",
        "Expected training time:\n",
        "- **A100 40GB**: ~3-5 hours for 60 epochs\n",
        "- **V100 32GB**: ~6-10 hours\n",
        "- **T4 16GB**: May need to reduce batch size to 8-16\n",
        "\n",
        "The training will:\n",
        "- Save best model (regular) to Google Drive automatically\n",
        "- Save best EMA model separately (`panderm_best_ema.pth`)\n",
        "- Save checkpoints every 5 epochs with EMA state\n",
        "- Stop early if no improvement for **20 epochs** (increased patience)\n",
        "- Use gradient accumulation for effective larger batches\n",
        "- Apply **Mixup/CutMix** augmentation (50% probability)\n",
        "- Track both regular and **EMA validation metrics**\n",
        "- Use **CosineAnnealingWarmRestarts** scheduler with 5-epoch warmup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hq2IntpYnv-K"
      },
      "outputs": [],
      "source": [
        "# Start training\n",
        "print(\"üöÄ Starting PanDerm training...\")\n",
        "print(\"‚ö†Ô∏è This will take several hours. Don't close the browser tab!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Train the model\n",
        "history = trainer.train()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üéâ PANDERM TRAINING COMPLETED!\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3kcGG1Anv-K"
      },
      "source": [
        "## 1Ô∏è‚É£2Ô∏è‚É£ View Training Results\n",
        "\n",
        "Analyze training history and visualize performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "web8QcQ-nv-K"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load training history\n",
        "history_path = f'{CHECKPOINT_DIR}/panderm_history.csv'\n",
        "if os.path.exists(history_path):\n",
        "    history_df = pd.read_csv(history_path)\n",
        "else:\n",
        "    # Use in-memory history if file not found\n",
        "    history_df = pd.DataFrame(history)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PANDERM TRAINING SUMMARY (with EMA)\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nTotal epochs: {len(history_df)}\")\n",
        "print(f\"Best Macro F1 (regular): {history_df['val_f1_macro'].max():.4f}\")\n",
        "if 'val_f1_macro_ema' in history_df.columns:\n",
        "    print(f\"Best Macro F1 (EMA):     {history_df['val_f1_macro_ema'].max():.4f}\")\n",
        "    best_model = \"EMA\" if history_df['val_f1_macro_ema'].max() > history_df['val_f1_macro'].max() else \"Regular\"\n",
        "    print(f\"Recommended model: {best_model}\")\n",
        "print(f\"Final Train Loss: {history_df['train_loss'].iloc[-1]:.4f}\")\n",
        "print(f\"Final Val Loss: {history_df['val_loss'].iloc[-1]:.4f}\")\n",
        "\n",
        "# Plot training curves\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Loss curves\n",
        "axes[0, 0].plot(history_df['train_loss'], label='Train Loss', linewidth=2)\n",
        "axes[0, 0].plot(history_df['val_loss'], label='Val Loss', linewidth=2)\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('Loss')\n",
        "axes[0, 0].set_title('Training and Validation Loss (PanDerm)')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# F1 scores (including EMA if available)\n",
        "axes[0, 1].plot(history_df['val_f1_macro'], label='Macro F1', linewidth=2, color='green')\n",
        "if 'val_f1_macro_ema' in history_df.columns:\n",
        "    axes[0, 1].plot(history_df['val_f1_macro_ema'], label='EMA F1', linewidth=2, color='blue', linestyle='--')\n",
        "    best_f1 = max(history_df['val_f1_macro'].max(), history_df['val_f1_macro_ema'].max())\n",
        "else:\n",
        "    best_f1 = history_df['val_f1_macro'].max()\n",
        "axes[0, 1].axhline(y=best_f1, color='r', linestyle=':', label=f'Best: {best_f1:.4f}')\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('F1 Score')\n",
        "axes[0, 1].set_title('Validation Macro F1 Score (Regular vs EMA)')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Learning rate (CosineAnnealingWarmRestarts)\n",
        "axes[1, 0].plot(history_df['learning_rate'], linewidth=2, color='purple')\n",
        "axes[1, 0].set_xlabel('Epoch')\n",
        "axes[1, 0].set_ylabel('Learning Rate')\n",
        "axes[1, 0].set_title('Learning Rate Schedule (CosineWarmRestarts)')\n",
        "axes[1, 0].set_yscale('log')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Loss comparison at best epoch\n",
        "best_epoch = history_df['val_f1_macro'].idxmax()\n",
        "axes[1, 1].bar(['Train Loss', 'Val Loss'],\n",
        "               [history_df.loc[best_epoch, 'train_loss'],\n",
        "                history_df.loc[best_epoch, 'val_loss']],\n",
        "               color=['blue', 'orange'])\n",
        "axes[1, 1].set_title(f'Loss at Best Epoch ({best_epoch+1})')\n",
        "axes[1, 1].set_ylabel('Loss')\n",
        "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{DRIVE_ROOT}/panderm_training_curves.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n‚úÖ Training curves saved to: {DRIVE_ROOT}/panderm_training_curves.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o7wDO7qnv-K"
      },
      "source": [
        "## 1Ô∏è‚É£3Ô∏è‚É£ Save Model Info\n",
        "\n",
        "Document training results for team reference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yymg4Zvinv-K"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Create model info file\n",
        "best_epoch = history_df['val_f1_macro'].idxmax()\n",
        "best_macro_f1 = history_df['val_f1_macro'].max()\n",
        "\n",
        "model_info = f\"\"\"# PanDerm Training Results\n",
        "\n",
        "**Date**: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
        "**GPU**: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\n",
        "**Total Epochs**: {len(history_df)}\n",
        "**Best Epoch**: {best_epoch + 1}\n",
        "**Best Macro F1**: {best_macro_f1:.4f}\n",
        "\n",
        "## Model Configuration\n",
        "\n",
        "- **Architecture**: Tri-Modal PanDerm Fusion\n",
        "- **Backbone**: {MODEL_CONFIG_PANDERM['model_name']}\n",
        "- **Embed Dim**: {MODEL_CONFIG_PANDERM['embed_dim']}\n",
        "- **TMCT Layers**: {MODEL_CONFIG_PANDERM.get('tmct_num_layers', 2)}\n",
        "- **Concept Tokens**: {MODEL_CONFIG_PANDERM['num_concept_tokens']}\n",
        "- **Auxiliary Heads**: {MODEL_CONFIG_PANDERM['use_auxiliary_heads']}\n",
        "- **Image Size**: {IMAGE_CONFIG_PANDERM['image_size']}\n",
        "- **Batch Size**: {BATCH_SIZE}\n",
        "\n",
        "## Training Configuration\n",
        "\n",
        "- **Base LR**: {TRAIN_CONFIG_PANDERM['base_lr']}\n",
        "- **LR Decay**: {TRAIN_CONFIG_PANDERM['backbone_lr_decay']}\n",
        "- **Gradient Accumulation**: {TRAIN_CONFIG_PANDERM.get('gradient_accumulation', 1)}\n",
        "- **Weight Decay**: {TRAIN_CONFIG_PANDERM['weight_decay']}\n",
        "\n",
        "## Loss Configuration\n",
        "\n",
        "- **Type**: Compound (Focal + Soft F1)\n",
        "- **Focal Weight**: {LOSS_CONFIG_PANDERM['focal_weight']}\n",
        "- **Soft F1 Weight**: {LOSS_CONFIG_PANDERM['soft_f1_weight']}\n",
        "- **Aux Loss Weight**: {LOSS_CONFIG_PANDERM['aux_loss_weight']}\n",
        "\n",
        "## Files\n",
        "\n",
        "- Best Model: `{CHECKPOINT_DIR}/panderm_best.pth`\n",
        "- Training History: `{CHECKPOINT_DIR}/panderm_history.csv`\n",
        "- Training Curves: `{DRIVE_ROOT}/panderm_training_curves.png`\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "1. Download panderm_best.pth from Google Drive\n",
        "2. Run inference on test set using `src/generate_submission_panderm.py`\n",
        "3. Consider ensemble with EfficientNet-B3 model\n",
        "4. Share results with team\n",
        "\"\"\"\n",
        "\n",
        "# Save model info\n",
        "info_path = f'{DRIVE_ROOT}/PANDERM_MODEL_INFO.md'\n",
        "with open(info_path, 'w') as f:\n",
        "    f.write(model_info)\n",
        "\n",
        "print(model_info)\n",
        "print(f\"\\n‚úÖ Model info saved to: {info_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZLd7LdXnv-K"
      },
      "source": [
        "## 1Ô∏è‚É£4Ô∏è‚É£ Download Trained Model\n",
        "\n",
        "Download the trained model and results to your local machine.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQZn2MZOnv-K"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Option 1: Download directly (may be slow for large files)\n",
        "print(\"Downloading files...\")\n",
        "print(\"‚ö†Ô∏è This may take a while for large model files\")\n",
        "\n",
        "# Download best model (regular)\n",
        "try:\n",
        "    files.download(f'{CHECKPOINT_DIR}/panderm_best.pth')\n",
        "    print(\"‚úÖ Downloaded: panderm_best.pth (regular model)\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not download model: {e}\")\n",
        "    print(f\"üìÅ Access it in Google Drive: {CHECKPOINT_DIR}/panderm_best.pth\")\n",
        "\n",
        "# Download best EMA model\n",
        "try:\n",
        "    files.download(f'{CHECKPOINT_DIR}/panderm_best_ema.pth')\n",
        "    print(\"‚úÖ Downloaded: panderm_best_ema.pth (EMA model)\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not download EMA model: {e}\")\n",
        "    print(f\"üìÅ Access it in Google Drive: {CHECKPOINT_DIR}/panderm_best_ema.pth\")\n",
        "\n",
        "# Download training history\n",
        "try:\n",
        "    files.download(f'{CHECKPOINT_DIR}/panderm_history.csv')\n",
        "    print(\"‚úÖ Downloaded: panderm_history.csv\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not download history: {e}\")\n",
        "\n",
        "# Download training curves\n",
        "try:\n",
        "    files.download(f'{DRIVE_ROOT}/panderm_training_curves.png')\n",
        "    print(\"‚úÖ Downloaded: panderm_training_curves.png\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not download curves: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üì¶ All files are also saved in Google Drive:\")\n",
        "print(f\"  üìÅ {DRIVE_ROOT}/\")\n",
        "print(f\"  üìÅ {CHECKPOINT_DIR}/\")\n",
        "print(\"  üìÑ panderm_best.pth (regular model)\")\n",
        "print(\"  üìÑ panderm_best_ema.pth (EMA model - often better)\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voSsVAPXnv-K"
      },
      "source": [
        "## üîÑ Resume Training (if interrupted)\n",
        "\n",
        "If your training was interrupted, you can resume from a checkpoint.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXWG_cv0nv-K"
      },
      "outputs": [],
      "source": [
        "# Uncomment and run this cell to resume training from a checkpoint\n",
        "\n",
        "# import glob\n",
        "#\n",
        "# # Find the latest checkpoint\n",
        "# checkpoints = glob.glob(f'{CHECKPOINT_DIR}/checkpoint_epoch_*.pth')\n",
        "# if checkpoints:\n",
        "#     latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
        "#     print(f\"Loading checkpoint: {latest_checkpoint}\")\n",
        "#\n",
        "#     # Load checkpoint\n",
        "#     checkpoint = torch.load(latest_checkpoint, map_location=device)\n",
        "#     model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#     trainer.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#     start_epoch = checkpoint['epoch'] + 1\n",
        "#\n",
        "#     print(f\"Resuming from epoch {start_epoch}\")\n",
        "#     # Continue training...\n",
        "# else:\n",
        "#     print(\"No checkpoint found. Starting fresh training.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD8U7wtvnv-K"
      },
      "source": [
        "---\n",
        "\n",
        "## üéâ Training Complete!\n",
        "\n",
        "### What to do next:\n",
        "\n",
        "1. **Download the trained model** from Google Drive:\n",
        "   - `panderm_best.pth` (regular model)\n",
        "   - `panderm_best_ema.pth` (EMA model - often better generalization)\n",
        "2. **Choose the best model**: Check the training summary to see which model (regular or EMA) has better F1\n",
        "3. **Run inference** on test set using `src/generate_submission_panderm.py`\n",
        "4. **Consider ensemble** with EfficientNet-B3 and XGBoost for better performance\n",
        "\n",
        "### Enhanced Training Features (v2):\n",
        "\n",
        "| Feature | Setting | Purpose |\n",
        "|---------|---------|---------|\n",
        "| Dropout | 0.3 | Stronger regularization |\n",
        "| DropPath | 0.1 | Stochastic depth in TMCT |\n",
        "| Mixup | Œ±=0.8 | Data augmentation |\n",
        "| CutMix | Œ±=1.0 | Data augmentation |\n",
        "| EMA | decay=0.9999 | Smoother, better generalization |\n",
        "| Scheduler | CosineWarmRestarts | Escape local minima |\n",
        "| Label Smoothing | 0.1 | Prevent overconfidence |\n",
        "| Early Stopping | 20 epochs | Allow more recovery time |\n",
        "\n",
        "### Tips for PanDerm Training:\n",
        "\n",
        "- **A100 40GB**: Use batch_size=32-48, gradient_accumulation=2 for effective batch of 64-96\n",
        "- **V100 32GB**: Use batch_size=24-32, gradient_accumulation=2-3\n",
        "- **T4 16GB**: Use batch_size=8-12, gradient_accumulation=4-6\n",
        "- **Memory**: PanDerm uses dual ViT backbones, so it's more memory-intensive than single-backbone models\n",
        "- **EMA Model**: Often generalizes better than the regular model - always check both!\n",
        "\n",
        "### Model Architecture Notes:\n",
        "\n",
        "- **Dual DermLIP Encoders**: Separate encoders for clinical and dermoscopic images allow specialized feature extraction\n",
        "- **MONET Concept Embedding**: Interpretable concept tokens from MONET probability scores\n",
        "- **TMCT Fusion with DropPath**: Cross-attention between visual features and concept tokens with stochastic depth\n",
        "- **Auxiliary Heads**: Deep supervision helps train the backbone more effectively\n",
        "\n",
        "### Expected Improvements (v2 vs v1):\n",
        "\n",
        "- **Reduced overfitting**: Train/Val gap should decrease from ~36% to <15%\n",
        "- **Better F1**: Expected improvement from 0.54 to 0.58-0.62\n",
        "- **More stable training**: F1 fluctuation should decrease with EMA\n",
        "- **Longer training**: Model can train longer before overfitting\n",
        "\n",
        "---\n",
        "\n",
        "**Happy Training! üöÄ**\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04a8d5f13cd147f49b41db49f8185aca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0562886e558b427aafc9d77127e1f567": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b1af0b652884dd094a18a867a160ddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f84066510a2443abcbb79c1b39ef43e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2ff42906b4ca45a88c7075302b6c6707",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "0b822554d2cc495797cff11095bd093a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfb8915d309e4990b986936592319e49",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_17881c0e151f4cc6972a88f5cb7264f1",
            "value": "‚Äá638/638‚Äá[00:00&lt;00:00,‚Äá77.6kB/s]"
          }
        },
        "1051480eb31c479c883713c7ccc37e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd155f9a58cc441097f1ac6b920b3e10",
            "max": 346284714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4217df9bc400404fad2563ba95564ca0",
            "value": 346284714
          }
        },
        "17881c0e151f4cc6972a88f5cb7264f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2801734acdb1431eaed0899a9ec2f0c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ff42906b4ca45a88c7075302b6c6707": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3acf2c2347ce4625b153d2b8075982c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ce7b36c0114495d816de194d5dc9553": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4217df9bc400404fad2563ba95564ca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44a7acb7bae7464aa99e3adaf9896d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ce7b36c0114495d816de194d5dc9553",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d6864af1c0e6491b9b8c7d4b9bd7f605",
            "value": "‚Äá784M/784M‚Äá[00:08&lt;00:00,‚Äá524MB/s]"
          }
        },
        "624541bfae03409e8a297c529b80261d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73ef5519fc0348e9a2a400a6efbb95f0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c6bcbd9608dc4d06975e406a01517b1e",
            "value": "open_clip_config.json:‚Äá100%"
          }
        },
        "6f84066510a2443abcbb79c1b39ef43e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73ef5519fc0348e9a2a400a6efbb95f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "742481e32db54d76aa0b3307170a1c11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92c7cb8322aa4eecaab50a12f9471c1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97cd603def3741cb9a591d11d9c0ac08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04a8d5f13cd147f49b41db49f8185aca",
            "max": 783694172,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_742481e32db54d76aa0b3307170a1c11",
            "value": 783694172
          }
        },
        "9961e12d8cdf4c64a172e6497b7f7e1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0562886e558b427aafc9d77127e1f567",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c336f53ee5074cd3876588ae29b61864",
            "value": "open_clip_model.safetensors:‚Äá100%"
          }
        },
        "99f61d9310f54264ae9b6e9516d34ea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d128986d7be24efd981209985ca64ae7",
            "max": 638,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8f5b4b58c6c43eb8017da8c3152e054",
            "value": 638
          }
        },
        "9d28ed34c5654efeb6e00359597b9c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9961e12d8cdf4c64a172e6497b7f7e1f",
              "IPY_MODEL_97cd603def3741cb9a591d11d9c0ac08",
              "IPY_MODEL_44a7acb7bae7464aa99e3adaf9896d58"
            ],
            "layout": "IPY_MODEL_dc039cbc06ff41bcb9824bf6423667a4"
          }
        },
        "a8f5b4b58c6c43eb8017da8c3152e054": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b367dda78211492abffff9d5956fae75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfb8915d309e4990b986936592319e49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c336f53ee5074cd3876588ae29b61864": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6bcbd9608dc4d06975e406a01517b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c73f90bdc7d946cfaab485d760d00fe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_624541bfae03409e8a297c529b80261d",
              "IPY_MODEL_99f61d9310f54264ae9b6e9516d34ea6",
              "IPY_MODEL_0b822554d2cc495797cff11095bd093a"
            ],
            "layout": "IPY_MODEL_2801734acdb1431eaed0899a9ec2f0c9"
          }
        },
        "d128986d7be24efd981209985ca64ae7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6864af1c0e6491b9b8c7d4b9bd7f605": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc039cbc06ff41bcb9824bf6423667a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbf7feeee66342c7b7d12e5d04a5293c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b367dda78211492abffff9d5956fae75",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3acf2c2347ce4625b153d2b8075982c5",
            "value": "‚Äá346M/346M‚Äá[00:02&lt;00:00,‚Äá303MB/s]"
          }
        },
        "fcf2944d3e87474cb1c2132fa77e83aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b1af0b652884dd094a18a867a160ddf",
              "IPY_MODEL_1051480eb31c479c883713c7ccc37e2b",
              "IPY_MODEL_fbf7feeee66342c7b7d12e5d04a5293c"
            ],
            "layout": "IPY_MODEL_92c7cb8322aa4eecaab50a12f9471c1b"
          }
        },
        "fd155f9a58cc441097f1ac6b920b3e10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
